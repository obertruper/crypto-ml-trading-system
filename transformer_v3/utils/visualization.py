"""
–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è Transformer v3
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ VisualizationCallback –≤ train_universal_transformer.py
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from tensorflow import keras
import logging
from pathlib import Path
from typing import Dict, List, Optional
import matplotlib
matplotlib.use('Agg')

from config import VISUALIZATION_PARAMS

logger = logging.getLogger(__name__)


class VisualizationCallback(keras.callbacks.Callback):
    """Callback –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, log_dir: Path, model_name: str, 
                 update_freq: int = 5, task: str = 'regression'):
        super().__init__()
        self.log_dir = Path(log_dir)
        self.model_name = model_name
        self.update_freq = update_freq
        self.task = task
        self.epoch_count = 0
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        self.plots_dir = self.log_dir / 'plots'
        self.plots_dir.mkdir(exist_ok=True)
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.history = {
            'loss': [],
            'val_loss': [],
            'lr': []
        }
        
        if task == 'regression':
            self.history.update({
                'mae': [],
                'val_mae': [],
                'rmse': [],
                'val_rmse': []
            })
        else:  # classification
            self.history.update({
                'accuracy': [],
                'val_accuracy': [],
                'precision': [],
                'val_precision': [],
                'recall': [],
                'val_recall': [],
                'auc': [],
                'val_auc': []
            })
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
        plt.style.use(VISUALIZATION_PARAMS['style'])
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É
        self.fig, self.axes = plt.subplots(2, 2, figsize=VISUALIZATION_PARAMS['figure_size'])
        self.fig.suptitle(f'Training Progress: {model_name}', fontsize=16)
        
    def on_epoch_end(self, epoch, logs=None):
        self.epoch_count += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        for key in self.history:
            if key == 'lr':
                # Learning rate
                lr = self.model.optimizer.learning_rate
                if hasattr(lr, 'numpy'):
                    self.history['lr'].append(lr.numpy())
                else:
                    self.history['lr'].append(float(lr))
            else:
                # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ logs
                value = logs.get(key, 0)
                self.history[key].append(value)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        self._save_metrics_csv()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏
        if self.epoch_count % self.update_freq == 0:
            self.update_plots()
    
    def _save_metrics_csv(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ CSV"""
        metrics_df = pd.DataFrame(self.history)
        metrics_path = self.log_dir / f'{self.model_name}_metrics.csv'
        metrics_df.to_csv(metrics_path, index=False)
    
    def update_plots(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
        epochs = range(1, len(self.history['loss']) + 1)
        
        # –û—á–∏—â–∞–µ–º –æ—Å–∏
        for ax in self.axes.flat:
            ax.clear()
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: Loss
        self.axes[0, 0].plot(epochs, self.history['loss'], 'b-', label='Train Loss', linewidth=2)
        self.axes[0, 0].plot(epochs, self.history['val_loss'], 'r-', label='Val Loss', linewidth=2)
        self.axes[0, 0].set_title('Model Loss')
        self.axes[0, 0].set_xlabel('Epoch')
        self.axes[0, 0].set_ylabel('Loss')
        self.axes[0, 0].legend()
        self.axes[0, 0].grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: –û—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
        if self.task == 'regression':
            self._plot_regression_metric(self.axes[0, 1], epochs)
        else:
            self._plot_classification_metric(self.axes[0, 1], epochs)
        
        # –ì—Ä–∞—Ñ–∏–∫ 3: Learning Rate
        self.axes[1, 0].plot(epochs, self.history['lr'], 'g-', linewidth=2)
        self.axes[1, 0].set_title('Learning Rate Schedule')
        self.axes[1, 0].set_xlabel('Epoch')
        self.axes[1, 0].set_ylabel('Learning Rate')
        self.axes[1, 0].set_yscale('log')
        self.axes[1, 0].grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._plot_statistics(self.axes[1, 1])
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        progress_path = self.plots_dir / 'training_progress.png'
        plt.savefig(progress_path, dpi=VISUALIZATION_PARAMS['save_dpi'], bbox_inches='tight')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º snapshot —ç–ø–æ—Ö–∏
        epoch_path = self.plots_dir / f'epoch_{self.epoch_count:03d}.png'
        plt.savefig(epoch_path, dpi=100)
        
        logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –æ–±–Ω–æ–≤–ª–µ–Ω: —ç–ø–æ—Ö–∞ {self.epoch_count}")
    
    def _plot_regression_metric(self, ax, epochs):
        """–ì—Ä–∞—Ñ–∏–∫ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
        ax.plot(epochs, self.history['mae'], 'b-', label='Train MAE', linewidth=2)
        ax.plot(epochs, self.history['val_mae'], 'r-', label='Val MAE', linewidth=2)
        ax.set_title('Mean Absolute Error (%)')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('MAE (%)')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_classification_metric(self, ax, epochs):
        """–ì—Ä–∞—Ñ–∏–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        ax.plot(epochs, self.history['accuracy'], 'b-', label='Train Accuracy', linewidth=2)
        ax.plot(epochs, self.history['val_accuracy'], 'r-', label='Val Accuracy', linewidth=2)
        
        if 'auc' in self.history:
            ax.plot(epochs, self.history['auc'], 'b--', label='Train AUC', linewidth=1)
            ax.plot(epochs, self.history['val_auc'], 'r--', label='Val AUC', linewidth=1)
        
        ax.set_title('Model Performance')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Score')
        ax.set_ylim(0, 1)
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_statistics(self, ax):
        """–ì—Ä–∞—Ñ–∏–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        ax.axis('off')
        
        if self.task == 'regression':
            stats_text = self._get_regression_stats()
        else:
            stats_text = self._get_classification_stats()
        
        ax.text(0.1, 0.5, stats_text, fontsize=12,
               verticalalignment='center', family='monospace',
               bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.5))
    
    def _get_regression_stats(self) -> str:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
        current_epoch = len(self.history['loss'])
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é —ç–ø–æ—Ö—É
        best_epoch = np.argmin(self.history['val_loss']) + 1
        
        stats = f"""
Current Epoch: {current_epoch}

Loss:
  Train:  {self.history['loss'][-1]:.4f}
  Val:    {self.history['val_loss'][-1]:.4f}
  
MAE (%):
  Train:  {self.history['mae'][-1]:.3f}%
  Val:    {self.history['val_mae'][-1]:.3f}%

RMSE (%):
  Train:  {self.history['rmse'][-1]:.3f}%
  Val:    {self.history['val_rmse'][-1]:.3f}%

Best Results:
  Val Loss: {min(self.history['val_loss']):.4f}
  Val MAE:  {min(self.history['val_mae']):.3f}%
  Epoch:    {best_epoch}

Learning Rate: {self.history['lr'][-1]:.2e}
"""
        return stats
    
    def _get_classification_stats(self) -> str:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        current_epoch = len(self.history['loss'])
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é —ç–ø–æ—Ö—É
        best_epoch = np.argmax(self.history['val_accuracy']) + 1 if self.history['val_accuracy'] else 0
        
        stats = f"""
Current Epoch: {current_epoch}

Loss:
  Train:  {self.history['loss'][-1]:.4f}
  Val:    {self.history['val_loss'][-1]:.4f}
  
Accuracy:
  Train:  {self.history['accuracy'][-1]:.3f}
  Val:    {self.history['val_accuracy'][-1]:.3f}

Precision:
  Train:  {self.history.get('precision', [0])[-1]:.3f}
  Val:    {self.history.get('val_precision', [0])[-1]:.3f}
  
Recall:
  Train:  {self.history.get('recall', [0])[-1]:.3f}
  Val:    {self.history.get('val_recall', [0])[-1]:.3f}

AUC:
  Train:  {self.history.get('auc', [0])[-1]:.3f}
  Val:    {self.history.get('val_auc', [0])[-1]:.3f}

Best Results:
  Val Loss: {min(self.history['val_loss']):.4f}
  Val Acc:  {max(self.history['val_accuracy']) if self.history['val_accuracy'] else 0:.3f}
  Epoch:    {best_epoch}

Learning Rate: {self.history['lr'][-1]:.2e}
"""
        return stats
    
    def on_train_end(self, logs=None):
        """–§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
        self.update_plots()
        plt.close(self.fig)
        logger.info("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


def plot_training_history(history: Dict, save_path: Path, model_name: str = "Model"):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    
    Args:
        history: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è (keras history.history)
        save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
    epochs = range(1, len(history['loss']) + 1)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle(f'Training History: {model_name}', fontsize=14)
    
    # Loss
    axes[0, 0].plot(epochs, history['loss'], 'b-', label='Train')
    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Validation')
    axes[0, 0].set_title('Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
    if 'mae' in history:
        # –†–µ–≥—Ä–µ—Å—Å–∏—è
        axes[0, 1].plot(epochs, history['mae'], 'b-', label='Train MAE')
        axes[0, 1].plot(epochs, history['val_mae'], 'r-', label='Val MAE')
        axes[0, 1].set_title('Mean Absolute Error')
        axes[0, 1].set_ylabel('MAE')
    elif 'accuracy' in history:
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        axes[0, 1].plot(epochs, history['accuracy'], 'b-', label='Train Acc')
        axes[0, 1].plot(epochs, history['val_accuracy'], 'r-', label='Val Acc')
        axes[0, 1].set_title('Accuracy')
        axes[0, 1].set_ylabel('Accuracy')
    
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    axes[1, 0].axis('off')
    axes[1, 1].axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")