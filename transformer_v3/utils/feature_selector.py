"""
Feature Selection –¥–ª—è XGBoost v3.0
"""

import pandas as pd
import numpy as np
import logging
from typing import List, Tuple, Dict
from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

logger = logging.getLogger(__name__)


class FeatureSelector:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    # –ò–µ—Ä–∞—Ä—Ö–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞
    FEATURE_HIERARCHY = {
        'primary': [  # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'rsi_val', 'rsi_ma', 'rsi_val_ma_10', 'rsi_val_ma_60',
            'macd_val', 'macd_signal', 'macd_hist', 'macd_signal_ratio',
            'bb_position', 'bb_width', 'bb_upper', 'bb_lower',
            'adx_val', 'adx_plus_di', 'adx_minus_di', 'adx_diff',
            'atr', 'atr_percent', 'volume_ratio', 'volume_ratio_ma',
            'stoch_k', 'stoch_d', 'stoch_signal',
            'williams_r', 'mfi', 'cci', 'cmf', 'obv', 'obv_slope'
        ],
        'secondary': [  # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å BTC –∏ —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ
            'btc_correlation_5', 'btc_correlation_20', 'btc_correlation_60',
            'btc_volatility', 'btc_volume_ratio', 'btc_price_ratio',
            'ema_15', 'sma_20', 'vwap', 'price_to_vwap',
            'sar', 'sar_distance', 'sar_trend',
            'ich_tenkan', 'ich_kijun', 'ich_senkou_a', 'ich_senkou_b'
        ],
        'auxiliary': [  # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ
            'market_regime_low_vol', 'market_regime_med_vol', 'market_regime_high_vol',
            'dow_sin', 'dow_cos', 'hour_sin', 'hour_cos',
            'is_btc', 'is_eth', 'is_bnb', 'is_doge', 'is_other'
        ]
    }
    
    def __init__(self, method: str = "importance", top_k: int = 50,
                 primary_ratio: float = 0.7, auxiliary_ratio: float = 0.2):
        """
        Args:
            method: –ú–µ—Ç–æ–¥ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (importance, rfe, mutual_info, chi2, hierarchical)
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞
            primary_ratio: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (0.7 = 70%)
            auxiliary_ratio: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (0.2 = 20%)
        """
        self.method = method
        self.top_k = top_k
        self.primary_ratio = primary_ratio
        self.auxiliary_ratio = auxiliary_ratio
        self.selected_features = []
        self.feature_scores = {}
        
    def select_features(self, X: pd.DataFrame, y: pd.Series, 
                       feature_names: List[str] = None, group_name: str = None) -> Tuple[pd.DataFrame, List[str]]:
        """
        –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            X: –ü—Ä–∏–∑–Ω–∞–∫–∏
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            feature_names: –ò–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            X_selected: DataFrame —Å –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            selected_features: –°–ø–∏—Å–æ–∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        if feature_names is None:
            feature_names = list(X.columns)
            
        logger.info(f"üîç –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ—Ç–æ–¥–æ–º: {self.method}")
        logger.info(f"   –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
        
        if self.method == "importance":
            selected_features = self._select_by_importance(X, y, feature_names)
        elif self.method == "rfe":
            selected_features = self._select_by_rfe(X, y, feature_names)
        elif self.method == "mutual_info":
            selected_features = self._select_by_mutual_info(X, y, feature_names)
        elif self.method == "chi2":
            selected_features = self._select_by_chi2(X, y, feature_names)
        elif self.method == "combined":
            selected_features = self._select_combined(X, y, feature_names)
        elif self.method == "hierarchical":
            selected_features = self._select_hierarchical(X, y, feature_names, group_name)
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            selected_features = feature_names
            
        self.selected_features = selected_features
        
        # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        X_selected = X[selected_features]
        
        logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
        logger.info(f"üìä –¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {selected_features[:10]}")
        
        return X_selected, selected_features
        
    def _select_by_importance(self, X: pd.DataFrame, y: pd.Series, 
                            feature_names: List[str]) -> List[str]:
        """–û—Ç–±–æ—Ä –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ XGBoost"""
        # –û–±—É—á–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å XGBoost
        model = xgb.XGBClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        model.fit(X, y)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        importance = model.feature_importances_
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º scores
        self.feature_scores = dict(zip(importance_df['feature'], 
                                      importance_df['importance']))
        
        # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ø-K –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        selected = importance_df.head(self.top_k)['feature'].tolist()
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é –∫–æ—Ä—Ä–µ–∫—Ü–∏—é
        selected = self._apply_hierarchy_correction(selected, feature_names)
                
        return selected[:self.top_k]
        
    def _select_by_rfe(self, X: pd.DataFrame, y: pd.Series, 
                      feature_names: List[str]) -> List[str]:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º RandomForest –¥–ª—è RFE
        estimator = RandomForestClassifier(
            n_estimators=50,
            max_depth=5,
            random_state=42,
            n_jobs=-1
        )
        
        selector = RFE(estimator, n_features_to_select=self.top_k, step=0.1)
        selector.fit(X, y)
        
        # –û—Ç–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        selected = [feature_names[i] for i in range(len(feature_names)) 
                   if selector.support_[i]]
        
        return selected
        
    def _select_by_mutual_info(self, X: pd.DataFrame, y: pd.Series, 
                              feature_names: List[str]) -> List[str]:
        """–û—Ç–±–æ—Ä –ø–æ –≤–∑–∞–∏–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        selector = SelectKBest(mutual_info_classif, k=self.top_k)
        selector.fit(X, y)
        
        # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫—É –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        mask = selector.get_support()
        selected = [feature_names[i] for i in range(len(feature_names)) if mask[i]]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º scores
        self.feature_scores = dict(zip(feature_names, selector.scores_))
        
        return selected
        
    def _select_by_chi2(self, X: pd.DataFrame, y: pd.Series, 
                       feature_names: List[str]) -> List[str]:
        """–û—Ç–±–æ—Ä –ø–æ chi2 (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        X_positive = X - X.min() + 1e-6
        
        selector = SelectKBest(chi2, k=self.top_k)
        selector.fit(X_positive, y)
        
        # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫—É –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        mask = selector.get_support()
        selected = [feature_names[i] for i in range(len(feature_names)) if mask[i]]
        
        return selected
        
    def _select_combined(self, X: pd.DataFrame, y: pd.Series, 
                        feature_names: List[str]) -> List[str]:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
        importance_features = set(self._select_by_importance(X, y, feature_names))
        mutual_info_features = set(self._select_by_mutual_info(X, y, feature_names))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ)
        combined = list(importance_features.intersection(mutual_info_features))
        
        # –ï—Å–ª–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ, –±–µ—Ä–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        if len(combined) < self.top_k // 2:
            combined = list(importance_features.union(mutual_info_features))
            
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        if self.feature_scores:
            combined.sort(key=lambda x: self.feature_scores.get(x, 0), reverse=True)
            
        return combined[:self.top_k]
        
    def get_feature_importance_report(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç –æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if not self.feature_scores:
            return pd.DataFrame()
            
        df = pd.DataFrame(list(self.feature_scores.items()), 
                         columns=['feature', 'score'])
        df = df.sort_values('score', ascending=False).reset_index(drop=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –≤–∞–∂–Ω–æ—Å—Ç—å
        if df['score'].sum() > 0:
            df['normalized_score'] = df['score'] / df['score'].sum()
            df['cumulative_score'] = df['normalized_score'].cumsum()
        
        return df
    
    def _select_hierarchical(self, X: pd.DataFrame, y: pd.Series,
                           feature_names: List[str], group_name: str = None) -> List[str]:
        """–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞ —Å –∂–µ—Å—Ç–∫–∏–º–∏ –∫–≤–æ—Ç–∞–º–∏"""
        logger.info("üèóÔ∏è –ò—Å–ø–æ–ª—å–∑—É—é –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º 60/20/10/10")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        model = xgb.XGBClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X, y)
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        })
        
        # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        def get_category(feature):
            feature_lower = feature.lower()
            
            # 1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (80%)
            technical_patterns = [
                'rsi', 'macd', 'bb_', 'bollinger', 'adx', 'atr', 'stoch', 'williams', 
                'mfi', 'cci', 'cmf', 'obv', 'ema', 'sma', 'vwap', 'sar', 'ich_',
                'aroon', 'kc_', 'dc_', 'volume_ratio', 'price_momentum', 'volatility',
                'hl_spread', 'close_ratio', 'upper_shadow', 'lower_shadow',
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ—á–µ–π –∏ market regime –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ
                'hammer', 'doji', 'engulfing', 'consecutive', 'pattern', 'candle',
                'market_regime', 'regime', 'trend', 'divergence',
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                'gk_volatility', 'cumulative', 'position', 'log_return', 'log_volume',
                'price_to_', 'ratio', 'interaction', 'efficiency', 'signal'
            ]
            for pattern in technical_patterns:
                if pattern in feature_lower:
                    return 'technical'
            
            # 2. BTC –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (10%)
            btc_patterns = ['btc_', 'bitcoin']
            for pattern in btc_patterns:
                if pattern in feature_lower:
                    return 'btc_related'
            
            # 3. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (5% - —É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º)
            time_patterns = ['hour', 'dow', 'day', 'week', 'month', 'time', 'weekend']
            # –ò—Å–∫–ª—é—á–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ—á–µ–π –∏ —Ä–µ–∂–∏–º—ã —Ä—ã–Ω–∫–∞ –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö
            exclude_patterns = ['hammer', 'consecutive', 'market_regime', 'pattern', 'candle']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø—Ä–∏–∑–Ω–∞–∫
            is_temporal = False
            for pattern in time_patterns:
                if pattern in feature_lower:
                    is_temporal = True
                    break
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            if is_temporal:
                for exclude in exclude_patterns:
                    if exclude in feature_lower:
                        is_temporal = False
                        break
                        
            if is_temporal:
                return 'temporal'
            
            # 4. –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ (10%)
            return 'other'
        
        importance_df['category'] = importance_df['feature'].apply(get_category)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–µ–∫—É—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        logger.info("üìä –¢–µ–∫—É—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        for cat in ['technical', 'temporal', 'btc_related', 'other']:
            count = len(importance_df[importance_df['category'] == cat])
            logger.info(f"   {cat}: {count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        importance_df = importance_df.sort_values('importance', ascending=False)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–≤–æ—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≥—Ä—É–ø–ø—ã –º–æ–Ω–µ—Ç
        if group_name:
            # –ü–æ–ª—É—á–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è –≥—Ä—É–ø–ø—ã
            from ..data.preprocessor import DataPreprocessor
            preprocessor = DataPreprocessor(None)
            weights = preprocessor.get_group_weights(group_name)
            
            n_technical = int(self.top_k * weights.get('technical', 0.6))
            n_temporal = int(self.top_k * weights.get('temporal', 0.2))
            n_btc = int(self.top_k * weights.get('btc_related', 0.1))
            n_other = self.top_k - n_technical - n_temporal - n_btc
            
            logger.info(f"üéØ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –∫–≤–æ—Ç—ã –¥–ª—è –≥—Ä—É–ø–ø—ã '{group_name}':")
            logger.info(f"   Technical: {n_technical} ({weights.get('technical', 0.6)*100:.0f}%)")
            logger.info(f"   Temporal: {n_temporal} ({weights.get('temporal', 0.2)*100:.0f}%)")
            logger.info(f"   BTC: {n_btc} ({weights.get('btc_related', 0.1)*100:.0f}%)")
            logger.info(f"   Other: {n_other}")
        else:
            # –ò–ó–ú–ï–ù–ï–ù–û: –£–º–µ–Ω—å—à–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
            # –ë—ã–ª–æ: 60/20/10/10, —Å—Ç–∞–ª–æ: 80/5/10/5
            n_technical = int(self.top_k * 0.8)    # 80% - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ
            n_temporal = int(self.top_k * 0.05)    # 5% - —Ä–µ–∑–∫–æ —É–º–µ–Ω—å—à–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ
            n_btc = int(self.top_k * 0.1)          # 10% - –æ—Å—Ç–∞–≤–ª—è–µ–º BTC
            n_other = self.top_k - n_technical - n_temporal - n_btc  # 5%
        
        selected = []
        
        # 1. –û—Ç–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (80%)
        technical_features = importance_df[importance_df['category'] == 'technical']
        if len(technical_features) < n_technical:
            logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(technical_features)} < {n_technical}")
            selected.extend(technical_features['feature'].tolist())
            # –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –ª—É—á—à–∏–µ –∏–∑ –¥—Ä—É–≥–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π - —ç—Ç–æ –Ω–∞—Ä—É—à–∞–µ—Ç –∫–≤–æ—Ç—ã!
            # –ü—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ —á—Ç–æ –µ—Å—Ç—å
        else:
            selected.extend(technical_features.head(n_technical)['feature'].tolist())
        
        # 2. –û—Ç–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (5%)
        temporal_features = importance_df[importance_df['category'] == 'temporal']
        temporal_features = temporal_features[~temporal_features['feature'].isin(selected)]
        selected.extend(temporal_features.head(n_temporal)['feature'].tolist())
        
        # 3. –û—Ç–±–∏—Ä–∞–µ–º BTC-related –ø—Ä–∏–∑–Ω–∞–∫–∏ (10%)
        btc_features = importance_df[importance_df['category'] == 'btc_related']
        btc_features = btc_features[~btc_features['feature'].isin(selected)]
        selected.extend(btc_features.head(n_btc)['feature'].tolist())
        
        # 4. –û—Ç–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (10%)
        other_features = importance_df[importance_df['category'] == 'other']
        other_features = other_features[~other_features['feature'].isin(selected)]
        selected.extend(other_features.head(n_other)['feature'].tolist())
        
        # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –¥–æ–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        if len(selected) < self.top_k:
            remaining = self.top_k - len(selected)
            all_remaining = importance_df[~importance_df['feature'].isin(selected)]
            selected.extend(all_remaining.head(remaining)['feature'].tolist())
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        logger.info("‚úÖ –§–ò–ù–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        final_counts = {}
        for feature in selected:
            cat = get_category(feature)
            final_counts[cat] = final_counts.get(cat, 0) + 1
        
        for cat in ['technical', 'temporal', 'btc_related', 'other']:
            count = final_counts.get(cat, 0)
            percentage = count/len(selected)*100 if selected else 0
            target = {'technical': 80, 'temporal': 5, 'btc_related': 10, 'other': 5}.get(cat, 0)
            status = "‚úÖ" if abs(percentage - target) < 5 else "‚ö†Ô∏è"
            logger.info(f"   {cat}: {count} ({percentage:.1f}%) {status} [—Ü–µ–ª—å: {target}%]")
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        logger.info("\nüìã –¢–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        for cat in ['technical', 'temporal', 'btc_related', 'other']:
            cat_features = [f for f in selected if get_category(f) == cat][:5]
            if cat_features:
                logger.info(f"   {cat}: {', '.join(cat_features)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º scores
        self.feature_scores = dict(zip(importance_df['feature'], 
                                      importance_df['importance']))
        
        return selected
    
    def _apply_hierarchy_correction(self, selected: List[str], 
                                  feature_names: List[str]) -> List[str]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º"""
        # –°—á–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        def get_category(feature):
            for category, features in self.FEATURE_HIERARCHY.items():
                if any(f in feature for f in features):
                    return category
            return 'auxiliary'
        
        category_counts = {'primary': 0, 'secondary': 0, 'auxiliary': 0}
        for feature in selected:
            category = get_category(feature)
            category_counts[category] += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–≤–æ—Ç—ã
        n_primary_needed = int(self.top_k * self.primary_ratio)
        n_auxiliary_max = int(self.top_k * self.auxiliary_ratio)
        
        # –ï—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ primary –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if category_counts['primary'] < n_primary_needed:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞–∂–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            for feature in self.FEATURE_HIERARCHY['primary']:
                if feature in feature_names and feature not in selected:
                    selected.append(feature)
                    category_counts['primary'] += 1
                    if category_counts['primary'] >= n_primary_needed:
                        break
        
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ auxiliary –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if category_counts['auxiliary'] > n_auxiliary_max:
            # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ auxiliary –ø—Ä–∏–∑–Ω–∞–∫–∏
            auxiliary_to_remove = category_counts['auxiliary'] - n_auxiliary_max
            removed = 0
            selected_copy = selected.copy()
            for feature in reversed(selected_copy):
                if get_category(feature) == 'auxiliary':
                    selected.remove(feature)
                    removed += 1
                    if removed >= auxiliary_to_remove:
                        break
        
        return selected