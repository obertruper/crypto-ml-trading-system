"""
–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL –¥–ª—è Transformer v3
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ train_universal_transformer.py
"""

import pandas as pd
import psycopg2
from psycopg2.extras import execute_values, Json
import logging
from typing import Dict, Optional, List
import time

from config import Config, EXCLUDE_SYMBOLS

logger = logging.getLogger(__name__)


class DataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL"""
    
    def __init__(self, config: Config):
        self.config = config
        self.connection = None
        self._connect()
        
    def _connect(self):
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
        try:
            self.connection = psycopg2.connect(**self.config.database.connection_params)
            self.connection.autocommit = True
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL: {e}")
            raise
            
    def disconnect(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
        if self.connection:
            self.connection.close()
            logger.info("üì§ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL –∑–∞–∫—Ä—ã—Ç–æ")
            
    def __enter__(self):
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.disconnect()
        
    def fetch_dataframe(self, query: str, params=None) -> pd.DataFrame:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ DataFrame"""
        try:
            return pd.read_sql_query(query, self.connection, params=params)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {e}")
            raise
            
    def load_data(self, 
                  symbols: Optional[List[str]] = None,
                  limit: Optional[int] = None) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î
        
        Args:
            symbols: –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (–µ—Å–ª–∏ None - –≤—Å–µ —Å–∏–º–≤–æ–ª—ã)
            limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
            
        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        logger.info("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL...")
        start_time = time.time()
        
        # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = """
        SELECT 
            p.symbol, 
            p.timestamp, 
            p.datetime,
            p.technical_indicators,
            p.buy_expected_return,
            p.sell_expected_return,
            p.is_long_entry,
            p.is_short_entry,
            p.open, 
            p.high, 
            p.low, 
            p.close, 
            p.volume,
            r.market_type
        FROM processed_market_data p
        JOIN raw_market_data r ON p.raw_data_id = r.id
        WHERE p.technical_indicators IS NOT NULL
          AND r.market_type = 'futures'
        """
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        conditions = []
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã
        if EXCLUDE_SYMBOLS:
            exclude_list = "', '".join(EXCLUDE_SYMBOLS)
            conditions.append(f"p.symbol NOT IN ('{exclude_list}')")
            
        # –§–∏–ª—å—Ç—Ä –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º —Å–∏–º–≤–æ–ª–∞–º
        if symbols:
            symbols_list = "', '".join(symbols)
            conditions.append(f"p.symbol IN ('{symbols_list}')")
            
        if conditions:
            query += " AND " + " AND ".join(conditions)
            
        query += " ORDER BY p.symbol, p.timestamp"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if limit:
            query += f" LIMIT {limit}"
            
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        df = self.fetch_dataframe(query)
        
        load_time = time.time() - start_time
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –∑–∞ {load_time:.2f} —Å–µ–∫")
        
        if len(df) == 0:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\!")
            
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        self._log_data_statistics(df)
        
        return df
        
    def load_symbols_list(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if EXCLUDE_SYMBOLS:
            # –°–æ–∑–¥–∞–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –¥–ª—è IN –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
            placeholders = ','.join(['%s'] * len(EXCLUDE_SYMBOLS))
            query = f"""
            SELECT DISTINCT p.symbol
            FROM processed_market_data p
            JOIN raw_market_data r ON p.raw_data_id = r.id
            WHERE p.technical_indicators IS NOT NULL
              AND r.market_type = 'futures'
              AND p.symbol NOT IN ({placeholders})
            ORDER BY p.symbol
            """
            df = self.fetch_dataframe(query, EXCLUDE_SYMBOLS)
        else:
            query = """
            SELECT DISTINCT p.symbol
            FROM processed_market_data p
            JOIN raw_market_data r ON p.raw_data_id = r.id
            WHERE p.technical_indicators IS NOT NULL
              AND r.market_type = 'futures'
            ORDER BY p.symbol
            """
            df = self.fetch_dataframe(query)
        
        return df['symbol'].tolist()
        
    def load_symbol_data(self, symbol: str) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞"""
        return self.load_data(symbols=[symbol])
        
    def load_symbol_updates(self, symbol: str, after_timestamp: int) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –ø–æ—Å–ª–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ timestamp"""
        logger.info(f"üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –¥–ª—è {symbol} –ø–æ—Å–ª–µ {pd.to_datetime(after_timestamp, unit='ms')}")
        
        query = """
        SELECT 
            p.symbol, 
            p.timestamp, 
            p.datetime,
            p.technical_indicators,
            p.buy_expected_return,
            p.sell_expected_return,
            p.is_long_entry,
            p.is_short_entry,
            p.open, 
            p.high, 
            p.low, 
            p.close, 
            p.volume,
            r.market_type
        FROM processed_market_data p
        JOIN raw_market_data r ON p.raw_data_id = r.id
        WHERE p.technical_indicators IS NOT NULL
          AND r.market_type = 'futures'
          AND p.symbol = %s
          AND p.timestamp > %s
        ORDER BY p.timestamp
        """
        
        df = self.fetch_dataframe(query, (symbol, after_timestamp))
        
        if len(df) > 0:
            logger.info(f"üÜï –ù–∞–π–¥–µ–Ω–æ {len(df)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è {symbol}")
        
        return df
        
    def _log_data_statistics(self, df: pd.DataFrame):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–∞–Ω–Ω—ã–º"""
        symbol_counts = df['symbol'].value_counts()
        
        logger.info("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–∏–º–≤–æ–ª–∞–º:")
        logger.info(f"   –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(symbol_counts)}")
        logger.info(f"   –°—Ä–µ–¥–Ω–µ–µ –∑–∞–ø–∏—Å–µ–π –Ω–∞ —Å–∏–º–≤–æ–ª: {symbol_counts.mean():.0f}")
        
        # –¢–æ–ø-10 —Å–∏–º–≤–æ–ª–æ–≤
        logger.info("   –¢–æ–ø-10 —Å–∏–º–≤–æ–ª–æ–≤:")
        for symbol, count in symbol_counts.head(10).items():
            logger.info(f"     {symbol}: {count:,} –∑–∞–ø–∏—Å–µ–π")
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ expected returns
        if 'buy_expected_return' in df.columns:
            buy_stats = df['buy_expected_return'].describe()
            sell_stats = df['sell_expected_return'].describe()
            
            logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ expected returns:")
            logger.info(f"   Buy - mean: {buy_stats['mean']:.3f}%, std: {buy_stats['std']:.3f}%")
            logger.info(f"   Buy - min/max: {buy_stats['min']:.3f}% / {buy_stats['max']:.3f}%")
            logger.info(f"   Sell - mean: {sell_stats['mean']:.3f}%, std: {sell_stats['std']:.3f}%")
            logger.info(f"   Sell - min/max: {sell_stats['min']:.3f}% / {sell_stats['max']:.3f}%")
            
    def check_data_quality(self, df: pd.DataFrame) -> Dict[str, any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
        quality_report = {
            'total_records': len(df),
            'unique_symbols': df['symbol'].nunique(),
            'date_range': {
                'start': df['datetime'].min(),
                'end': df['datetime'].max()
            },
            'missing_values': {},
            'outliers': {}
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for col in ['buy_expected_return', 'sell_expected_return']:
            if col in df.columns:
                missing = df[col].isna().sum()
                quality_report['missing_values'][col] = missing
                
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
        for col in ['buy_expected_return', 'sell_expected_return']:
            if col in df.columns:
                outliers = ((df[col] < -1.1) | (df[col] > 5.8)).sum()
                quality_report['outliers'][col] = outliers
                
        return quality_report