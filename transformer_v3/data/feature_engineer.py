"""
Feature Engineering –¥–ª—è XGBoost v3.0
"""

import pandas as pd
import numpy as np
import logging
from typing import List, Dict, Optional
from sklearn.preprocessing import StandardScaler

from config import Config, FEATURE_CONFIG, TOP_SYMBOLS
from config.constants import (
    EPSILON, EPSILON_PRICE, EPSILON_STD,
    MARKET_FEATURES, OHLC_FEATURES, DIVERGENCE_PARAMS,
    BTC_DATA_PARAMS
)

logger = logging.getLogger(__name__)


class FeatureEngineer:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    def __init__(self, config: Config):
        self.config = config
        self.feature_config = FEATURE_CONFIG
        self.created_features = []
        
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        logger.info("üîÑ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        original_features = df.shape[1]
        
        # 1. –†—ã–Ω–æ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df = self._create_market_features(df)
        
        # 2. OHLC –ø—Ä–∏–∑–Ω–∞–∫–∏
        df = self._create_ohlc_features(df)
        
        # 3. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df = self._create_time_features(df)
        
        # 4. Symbol one-hot encoding
        df = self._create_symbol_features(df)
        
        # 5. –ë–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df = self._create_binary_features(df)
        
        # 6. –í–∑–≤–µ—à–µ–Ω–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        df = self._create_weighted_features(df)
        
        # 7. –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        df = self._create_rolling_features(df)
        
        # 8. –î–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏
        df = self._create_divergence_features(df)
        
        # 9. –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ—á–µ–π
        df = self._create_candle_patterns(df)
        
        # 10. Volume profile
        df = self._create_volume_profile_features(df)
        
        # 11. Price action –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        df = self._create_price_action_patterns(df)
        
        # 12. –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df = self._create_microstructure_features(df)
        
        # 13. –ú–µ–∂—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df = self._create_cross_timeframe_features(df)
        
        # –í–ê–ñ–ù–û: –î–µ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è DataFrame –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info("üîß –î–µ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è DataFrame...")
        df = df.copy()  # –≠—Ç–æ —É—Å—Ç—Ä–∞–Ω—è–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        logger.info("‚úÖ –î–µ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        df = self._remove_duplicate_features(df)
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –ø–æ—è–≤–∏—Ç—å—Å—è –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df = self._handle_new_nans(df)
        
        # –£–¥–∞–ª—è–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –î–û –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        df = self._remove_constant_features(df)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df = self.validate_features(df)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        new_features = df.shape[1] - original_features
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {new_features} –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        logger.info(f"üìä –ò—Ç–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {df.shape[1]}")
        
        return df
        
    def _create_market_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üåç –°–æ–∑–¥–∞–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ BTC –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        if 'btc_close' not in df.columns:
            from data.btc_data_loader import BTCDataLoader
            btc_loader = BTCDataLoader(self.config)
            df = btc_loader.load_btc_data(df)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
            if 'btc_close' not in df.columns:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ BTC, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
                return df
            
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å BTC
        for window in MARKET_FEATURES['correlation_windows']:
            df[f'btc_correlation_{window}'] = df['close'].rolling(window).corr(df['btc_close'])
        
        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
        for period_name, period_candles in MARKET_FEATURES['return_periods'].items():
            df[f'btc_return_{period_name}'] = df['btc_close'].pct_change(period_candles)
        
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å BTC
        df['btc_volatility'] = df['btc_return_1h'].rolling(20).std()
        
        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–ª–∞
        df['relative_strength_btc'] = df['close'].pct_change(MARKET_FEATURES['return_periods']['1h']) / (df['btc_return_1h'] + EPSILON)
        
        # –†—ã–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–ª—å–∑—è—â–∏–µ –∫–≤–∞–Ω—Ç–∏–ª–∏ –≤–º–µ—Å—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        volatility_quantiles = MARKET_FEATURES['volatility_quantiles']  # [0.33, 0.67]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∫–≤–∞–Ω—Ç–∏–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 —Å–≤–µ—á–µ–π)
        window_size = 500
        df['btc_vol_low_threshold'] = df['btc_volatility'].rolling(window=window_size, min_periods=100).quantile(volatility_quantiles[0])
        df['btc_vol_high_threshold'] = df['btc_volatility'].rolling(window=window_size, min_periods=100).quantile(volatility_quantiles[1])
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω–æ–π –∏–∑ –ø–µ—Ä–≤—ã—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        df['btc_vol_low_threshold'] = df['btc_vol_low_threshold'].fillna(df['btc_volatility'].iloc[:window_size].quantile(volatility_quantiles[0]))
        df['btc_vol_high_threshold'] = df['btc_vol_high_threshold'].fillna(df['btc_volatility'].iloc[:window_size].quantile(volatility_quantiles[1]))
        
        df['market_regime_low_vol'] = (df['btc_volatility'] < df['btc_vol_low_threshold']).astype(int)
        df['market_regime_med_vol'] = ((df['btc_volatility'] >= df['btc_vol_low_threshold']) & 
                                       (df['btc_volatility'] < df['btc_vol_high_threshold'])).astype(int)
        df['market_regime_high_vol'] = (df['btc_volatility'] >= df['btc_vol_high_threshold']).astype(int)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        df.drop(['btc_vol_low_threshold', 'btc_vol_high_threshold'], axis=1, inplace=True)
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        market_features = ['btc_correlation_20', 'btc_correlation_60', 'btc_return_1h', 
                          'btc_return_4h', 'btc_volatility', 'relative_strength_btc']
        for col in market_features:
            df[col] = df[col].fillna(0)
            
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
        df.drop('btc_close', axis=1, inplace=True)
        
        logger.info("‚úÖ –†—ã–Ω–æ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
        return df
        
    def _create_ohlc_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ OHLC –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ OHLC –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã
        df['open_ratio'] = df['open'] / df['close']
        df['high_ratio'] = df['high'] / df['close']
        df['low_ratio'] = df['low'] / df['close']
        
        # –°–ø—Ä–µ–¥—ã –∏ —Ä–∞–∑–º–µ—Ä—ã
        df['hl_spread'] = (df['high'] - df['low']) / df['close']
        df['body_size'] = abs(df['close'] - df['open']) / df['close']
        
        # –¢–µ–Ω–∏ —Å–≤–µ—á–µ–π
        df['upper_shadow'] = (df['high'] - df[['open', 'close']].max(axis=1)) / df['close']
        df['lower_shadow'] = (df[['open', 'close']].min(axis=1) - df['low']) / df['close']
        
        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–≤–µ—á–∏
        df['is_bullish'] = (df['close'] > df['open']).astype(int)
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ 0 –∏ 1
        df['is_bullish'] = df['is_bullish'].clip(0, 1)
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        df['log_return'] = np.log(df['close'] / df['open'].replace(0, EPSILON_PRICE))
        df['log_volume'] = np.log1p(df['volume'])
        
        # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö
        if 'ema_15' in df.columns:
            df['price_to_ema15'] = (df['close'] - df['ema_15']) / df['ema_15']
            # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è EMA50 —á–µ—Ä–µ–∑ EMA15
            ema50_approx = df['ema_15'] * OHLC_FEATURES['ema50_multiplier']
            df['price_to_ema50'] = (df['close'] - ema50_approx) / ema50_approx
            
        # VWAP approximation —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º –æ–∫–Ω–æ–º (—Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ –¥–∞–Ω–Ω—ã–µ)
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º expanding —Å min_periods –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ VWAP
        typical_price = (df['high'] + df['low'] + df['close']) / 3
        df['vwap'] = (df['volume'] * typical_price).expanding(min_periods=1).sum() / df['volume'].expanding(min_periods=1).sum()
        df['price_to_vwap'] = (df['close'] - df['vwap']) / df['vwap']
        
        return df
        
    def _create_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üïê –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º timestamp –≤ datetime
        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —á–∞—Å–∞
        df['hour'] = df['datetime'].dt.hour
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        
        # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –¥–Ω—è –Ω–µ–¥–µ–ª–∏
        df['day_of_week'] = df['datetime'].dt.dayofweek
        df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        
        # –í—ã—Ö–æ–¥–Ω—ã–µ
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        df.drop(['datetime', 'hour', 'day_of_week'], axis=1, inplace=True)
        
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
        return df
        
    def _create_symbol_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤"""
        if 'symbol' not in df.columns:
            return df
            
        logger.info("üè∑Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ symbol –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # One-hot encoding –¥–ª—è —Ç–æ–ø —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ –∫–æ–Ω—Å—Ç–∞–Ω—Ç
        for symbol in TOP_SYMBOLS:
            col_name = f"is_{symbol.replace('USDT', '').lower()}"
            df[col_name] = (df['symbol'] == symbol).astype(int)
            
        return df
        
    def _create_binary_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üî¢ –°–æ–∑–¥–∞–Ω–∏–µ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        thresholds = self.feature_config['binary_thresholds']
        
        # RSI —É—Å–ª–æ–≤–∏—è
        if 'rsi_val' in df.columns:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –≤–æ–æ–±—â–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö
            oversold_exists = (df['rsi_val'] < thresholds['rsi_oversold']).any()
            overbought_exists = (df['rsi_val'] > thresholds['rsi_overbought']).any()
            
            if oversold_exists:
                df['rsi_oversold'] = (df['rsi_val'] < thresholds['rsi_oversold']).astype(int)
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–π RSI < {thresholds['rsi_oversold']}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º rsi_oversold")
                
            if overbought_exists:
                df['rsi_overbought'] = (df['rsi_val'] > thresholds['rsi_overbought']).astype(int)
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–π RSI > {thresholds['rsi_overbought']}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º rsi_overbought")
            
        # MACD —É—Å–ª–æ–≤–∏–µ
        if 'macd_hist' in df.columns:
            df['macd_bullish'] = (df['macd_hist'] > thresholds['macd_bullish']).astype(int)
            
        # –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
        if 'adx_val' in df.columns:
            strong_trend_exists = (df['adx_val'] > thresholds['strong_trend']).any()
            if strong_trend_exists:
                df['strong_trend'] = (df['adx_val'] > thresholds['strong_trend']).astype(int)
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–π ADX > {thresholds['strong_trend']}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º strong_trend")
            
        # –í—Å–ø–ª–µ—Å–∫ –æ–±—ä–µ–º–∞
        if 'volume_ratio' in df.columns:
            df['volume_spike'] = (df['volume_ratio'] > thresholds['volume_spike']).astype(int)
            
        # –ü–æ–∑–∏—Ü–∏—è –≤ Bollinger Bands
        if 'bb_position' in df.columns:
            df['bb_near_lower'] = (df['bb_position'] < thresholds['bb_near_lower']).astype(int)
            df['bb_near_upper'] = (df['bb_position'] > thresholds['bb_near_upper']).astype(int)
            
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ—á–µ–π
        candle_params = OHLC_FEATURES['candle_patterns']
        df['is_hammer'] = ((df['body_size'] < candle_params['hammer_body_size']) & 
                          (df['lower_shadow'] > df['body_size'] * candle_params['hammer_shadow_ratio'])).astype(int)
        df['is_doji'] = (df['body_size'] < candle_params['doji_body_size']).astype(int)
        
        return df
        
    def _create_weighted_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        created_count = 0
        
        # RSI + MACD –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
        if 'rsi_val' in df.columns and 'macd_hist' in df.columns:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
            rsi_norm = (df['rsi_val'] - 50) / 50  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –≤–æ–∫—Ä—É–≥ 0
            macd_norm = df['macd_hist'] / (df['macd_hist'].std() + EPSILON_STD)
            df['rsi_macd_interaction'] = rsi_norm * macd_norm
            created_count += 1
            
        # Volume + Volatility –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
        if 'volume_ratio' in df.columns and 'atr' in df.columns:
            df['volume_volatility_interaction'] = df['volume_ratio'] * df['atr']
            created_count += 1
            
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if 'rsi_val' in df.columns and 'adx_val' in df.columns:
            df['rsi_to_adx'] = df['rsi_val'] / (df['adx_val'] + 1)
            created_count += 1
            
        if 'volume' in df.columns and 'atr' in df.columns:
            df['volume_to_volatility'] = df['volume'] / (df['atr'] + EPSILON)
            created_count += 1
            
        if 'close' in df.columns and 'sar' in df.columns:
            df['price_momentum_ratio'] = (df['close'] - df['sar']) / df['close']
            created_count += 1
            
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_count} –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        return df
        
    def _create_rolling_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫"""
        logger.info("üìä –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫...")
        
        windows = self.feature_config['rolling_windows']
        
        # –î–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        indicators = ['rsi_val', 'adx_val', 'volume_ratio']
        
        for indicator in indicators:
            if indicator in df.columns:
                for window in windows:
                    # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
                    df[f'{indicator}_ma_{window}'] = df[indicator].rolling(window).mean()
                    # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ç–¥
                    df[f'{indicator}_std_{window}'] = df[indicator].rolling(window).std()
                    
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        for col in df.columns:
            if '_ma_' in col or '_std_' in col:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ ffill –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É–¥—É—â–µ–≥–æ
                # –î–ª—è –Ω–∞—á–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤–æ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                df[col] = df[col].fillna(method='ffill').fillna(df[col].iloc[df[col].first_valid_index()] if df[col].first_valid_index() is not None else 0)
                
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
        return df
        
    def _create_divergence_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–π"""
        logger.info("üîÑ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–π...")
        
        window = self.feature_config['divergence_window']
        
        # RSI –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
        if 'rsi_val' in df.columns and 'close' in df.columns:
            # –ë—ã—á—å—è –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è: —Ü–µ–Ω–∞ –ø–∞–¥–∞–µ—Ç, RSI —Ä–∞—Å—Ç–µ—Ç
            price_change = df['close'].pct_change(window)
            rsi_change = df['rsi_val'].pct_change(window)
            
            df['rsi_bullish_divergence'] = (
                (price_change < -DIVERGENCE_PARAMS['price_change_threshold']) & 
                (rsi_change > DIVERGENCE_PARAMS['rsi_change_threshold'])
            ).astype(int)
            df['rsi_bearish_divergence'] = (
                (price_change > DIVERGENCE_PARAMS['price_change_threshold']) & 
                (rsi_change < -DIVERGENCE_PARAMS['rsi_change_threshold'])
            ).astype(int)
            
        # Volume-Price –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
        if 'volume' in df.columns:
            volume_change = df['volume'].pct_change(window)
            df['volume_price_divergence'] = (
                (abs(price_change) > DIVERGENCE_PARAMS['volume_price_threshold']) & 
                (volume_change < DIVERGENCE_PARAMS['volume_change_threshold'])
            ).astype(int)
            
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏")
        return df
        
    def _create_candle_patterns(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å–≤–µ—á–µ–π"""
        logger.info("üïØÔ∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å–≤–µ—á–µ–π...")
        
        # Bullish Engulfing
        df['prev_close'] = df['close'].shift(1)
        df['prev_open'] = df['open'].shift(1)
        
        df['bullish_engulfing'] = (
            (df['prev_close'] < df['prev_open']) &  # –ü—Ä–µ–¥—ã–¥—É—â–∞—è —Å–≤–µ—á–∞ –º–µ–¥–≤–µ–∂—å—è
            (df['close'] > df['open']) &             # –¢–µ–∫—É—â–∞—è —Å–≤–µ—á–∞ –±—ã—á—å—è
            (df['open'] < df['prev_close']) &        # –û—Ç–∫—Ä—ã—Ç–∏–µ –Ω–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è
            (df['close'] > df['prev_open'])          # –ó–∞–∫—Ä—ã—Ç–∏–µ –≤—ã—à–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è
        ).astype(int)
        
        # Bearish Engulfing
        df['bearish_engulfing'] = (
            (df['prev_close'] > df['prev_open']) &   # –ü—Ä–µ–¥—ã–¥—É—â–∞—è —Å–≤–µ—á–∞ –±—ã—á—å—è
            (df['close'] < df['open']) &             # –¢–µ–∫—É—â–∞—è —Å–≤–µ—á–∞ –º–µ–¥–≤–µ–∂—å—è
            (df['open'] > df['prev_close']) &        # –û—Ç–∫—Ä—ã—Ç–∏–µ –≤—ã—à–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è
            (df['close'] < df['prev_open'])          # –ó–∞–∫—Ä—ã—Ç–∏–µ –Ω–∏–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è
        ).astype(int)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        df.drop(['prev_close', 'prev_open'], axis=1, inplace=True)
        
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ—á–µ–π")
        return df
        
    def _create_volume_profile_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ volume profile"""
        logger.info("üìà –î–æ–±–∞–≤–ª–µ–Ω–∏–µ volume profile...")
        
        # Volume weighted metrics
        if 'volume' in df.columns and 'close' in df.columns:
            # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ –æ–±—ä–µ–º–Ω–æ–º –ø—Ä–æ—Ñ–∏–ª–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–≤–µ—á–µ–π
            volume_sum_20 = df['volume'].rolling(20).sum()
            df['volume_position_20'] = df['volume'].rolling(20).apply(
                lambda x: (x.iloc[-1] / x.sum()) if x.sum() > 0 else 0
            )
            
            # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –æ–±—ä–µ–º –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º expanding –≤–º–µ—Å—Ç–æ cumsum –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            df['cumulative_volume_ratio'] = df['volume'].expanding(min_periods=1).sum() / df['volume'].expanding(min_periods=1).mean()
            
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã volume profile –ø—Ä–∏–∑–Ω–∞–∫–∏")
        return df
        
    def _create_price_action_patterns(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ price action –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        logger.info("üìä –î–æ–±–∞–≤–ª–µ–Ω–∏–µ price action –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤...")
        
        # Higher highs and lower lows
        df['higher_high'] = (df['high'] > df['high'].shift(1)).astype(int)
        df['lower_low'] = (df['low'] < df['low'].shift(1)).astype(int)
        
        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ higher highs/lower lows
        df['consecutive_hh'] = df['higher_high'].rolling(3).sum()
        df['consecutive_ll'] = df['lower_low'].rolling(3).sum()
        
        # Inside bar pattern
        df['inside_bar'] = ((df['high'] < df['high'].shift(1)) & 
                           (df['low'] > df['low'].shift(1))).astype(int)
        
        # Pin bar pattern (–¥–ª–∏–Ω–Ω–∞—è —Ç–µ–Ω—å)
        body_size = abs(df['close'] - df['open'])
        upper_wick = df['high'] - df[['close', 'open']].max(axis=1)
        lower_wick = df[['close', 'open']].min(axis=1) - df['low']
        
        df['pin_bar_bull'] = ((lower_wick > body_size * 2) & 
                              (upper_wick < body_size * 0.5)).astype(int)
        df['pin_bar_bear'] = ((upper_wick > body_size * 2) & 
                              (lower_wick < body_size * 0.5)).astype(int)
        
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã price action –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
        return df
        
    def _create_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üî¨ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # Bid-ask spread approximation (—á–µ—Ä–µ–∑ high-low)
        df['spread_approximation'] = (df['high'] - df['low']) / df['close']
        
        # Price efficiency ratio (–Ω–∞—Å–∫–æ–ª—å–∫–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ)
        price_change = df['close'].diff(10).abs()
        path_length = df['close'].diff().abs().rolling(10).sum()
        df['price_efficiency'] = price_change / (path_length + EPSILON)
        
        # Volume-price correlation
        df['volume_price_corr'] = df['close'].rolling(20).corr(df['volume'])
        
        # –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (Garman-Klass estimator)
        df['gk_volatility'] = np.sqrt(
            0.5 * np.log(df['high']/df['low'])**2 - 
            (2*np.log(2) - 1) * np.log(df['close']/df['open'])**2
        )
        
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
        return df
        
    def _create_cross_timeframe_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–µ–∂—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("‚è±Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ–∂—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –≠–º—É–ª—è—Ü–∏—è —Å—Ç–∞—Ä—à–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ —á–µ—Ä–µ–∑ –∞–≥—Ä–µ–≥–∞—Ü–∏—é
        # 1H = 4 —Å–≤–µ—á–∏ –ø–æ 15–º
        df['high_1h'] = df['high'].rolling(4).max()
        df['low_1h'] = df['low'].rolling(4).min()
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è close_1h
        df['close_1h'] = df['close'].rolling(4).apply(lambda x: x.iloc[-1] if len(x) == 4 else np.nan)
        
        # –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ 1H –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        df['position_in_1h_range'] = (df['close'] - df['low_1h']) / (df['high_1h'] - df['low_1h'] + EPSILON)
        
        # 4H = 16 —Å–≤–µ—á–µ–π –ø–æ 15–º
        df['high_4h'] = df['high'].rolling(16).max()
        df['low_4h'] = df['low'].rolling(16).min()
        
        # –¢—Ä–µ–Ω–¥ –Ω–∞ —Å—Ç–∞—Ä—à–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ
        df['trend_1h'] = (df['close'] > df['close'].shift(4)).astype(int)
        df['trend_4h'] = (df['close'] > df['close'].shift(16)).astype(int)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        df.drop(['high_1h', 'low_1h', 'close_1h', 'high_4h', 'low_4h'], axis=1, inplace=True)
        
        logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –º–µ–∂—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
        return df
        
    def _remove_duplicate_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        duplicated_cols = df.columns[df.T.duplicated()].tolist()
        
        if duplicated_cols:
            logger.info(f"   ‚úÖ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(duplicated_cols)}")
            logger.info(f"   üìã –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {duplicated_cols}")
            df = df.loc[:, ~df.T.duplicated()]
            
        return df
        
    def _handle_new_nans(self, df: pd.DataFrame) -> pd.DataFrame:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π, –ø–æ—è–≤–∏–≤—à–∏—Ö—Å—è –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # –î–µ–ª–∞–µ–º –∫–æ–ø–∏—é —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å SettingWithCopyWarning
        df = df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ NaN
        nan_cols = df.columns[df.isnull().any()].tolist()
        
        if nan_cols:
            logger.info(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –≤ {len(nan_cols)} –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö...")
            
            for col in nan_cols:
                if df[col].dtype in ['float64', 'float32', 'int64', 'int32']:
                    # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    if 'correlation' in col or 'return' in col:
                        # –î–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π - –∑–∞–ø–æ–ª–Ω—è–µ–º 0
                        df.loc[:, col] = df[col].fillna(0)
                    elif 'ratio' in col or 'volatility' in col:
                        # –î–ª—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ - –∑–∞–ø–æ–ª–Ω—è–µ–º 1
                        df.loc[:, col] = df[col].fillna(1)
                    else:
                        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º forward fill –≤–º–µ—Å—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –º–µ–¥–∏–∞–Ω—ã –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
                        # –°–Ω–∞—á–∞–ª–∞ forward fill, –ø–æ—Ç–æ–º backward fill –¥–ª—è –Ω–∞—á–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –∑–∞—Ç–µ–º 0 –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è
                        df.loc[:, col] = df[col].fillna(method='ffill').fillna(method='bfill').fillna(0)
                else:
                    # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö - –∑–∞–ø–æ–ª–Ω—è–µ–º 0
                    df.loc[:, col] = df[col].fillna(0)
                    
        return df
        
    def validate_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –î–µ–ª–∞–µ–º –∫–æ–ø–∏—é —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å SettingWithCopyWarning
        df = df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏
        numeric_df = df.select_dtypes(include=[np.number])
        inf_mask = np.isinf(numeric_df).any()
        inf_cols = numeric_df.columns[inf_mask].tolist()
        if inf_cols:
            logger.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∏ —Å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—è–º–∏: {inf_cols}")
            # –ó–∞–º–µ–Ω—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ –Ω–∞ NaN, –∑–∞—Ç–µ–º –Ω–∞ 0
            for col in inf_cols:
                df[col] = df[col].replace([np.inf, -np.inf], np.nan).fillna(0)
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –±–∏–Ω–∞—Ä–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        binary_patterns = ['is_', '_oversold', '_overbought', '_bullish', '_bearish', 
                          'strong_trend', 'volume_spike', 'bb_near_', '_engulfing', 
                          '_divergence', 'is_doji', 'is_hammer', 'is_weekend',
                          'market_regime_']
        
        binary_cols = []
        for col in df.columns:
            for pattern in binary_patterns:
                if pattern in col:
                    binary_cols.append(col)
                    break
                    
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        for col in binary_cols:
            if col in df.columns:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ 1, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤ 0
                # –î–ª—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –∫–∞–∫ is_bullish –≥–¥–µ –º–æ–∂–µ—Ç –±—ã—Ç—å -1
                if df[col].min() < 0:
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Å—á–∏—Ç–∞–µ–º –∏—Ö –∫–∞–∫ 0
                    df[col] = (df[col] > 0).astype(int)
                else:
                    # –ò–Ω–∞—á–µ –≤—Å–µ –Ω–µ-–Ω—É–ª–µ–≤—ã–µ –≤ 1
                    df[col] = (df[col] != 0).astype(int)
                
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        indicators_bounds = {
            'rsi_val': (0, 100),
            'stoch_k': (0, 100),
            'stoch_d': (0, 100),
            'williams_r': (-100, 0),
            'aroon_up': (0, 100),
            'aroon_down': (0, 100),
            'mfi': (0, 100)
        }
        
        for ind, (min_val, max_val) in indicators_bounds.items():
            if ind in df.columns:
                df[ind] = df[ind].clip(min_val, max_val)
                
        logger.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        return df
        
    def _remove_constant_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        logger.info("üîç –ü–æ–∏—Å–∫ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        exclude_cols = ['timestamp', 'symbol', 'open', 'high', 'low', 'close', 'volume', 
                       'buy_expected_return', 'sell_expected_return']
        check_cols = [col for col in df.columns if col not in exclude_cols]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        constant_features = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
        batch_size = 100
        for i in range(0, len(check_cols), batch_size):
            batch_cols = check_cols[i:i+batch_size]
            for col in batch_cols:
                if df[col].nunique(dropna=False) <= 1:
                    constant_features.append(col)
                    
        if constant_features:
            logger.warning(f"‚ö†Ô∏è –£–¥–∞–ª—è–µ–º {len(constant_features)} –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            if len(constant_features) < 10:
                logger.warning(f"   –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ: {constant_features}")
            else:
                logger.warning(f"   –ü–µ—Ä–≤—ã–µ 10: {constant_features[:10]}...")
            df = df.drop(columns=constant_features)
        else:
            logger.info("‚úÖ –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        return df