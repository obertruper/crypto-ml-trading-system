# Transformer v3.0 - ML Crypto Trading System

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

Transformer v3.0 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏—é —É—Å–ø–µ—à–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã XGBoost v3.0 –¥–ª—è **Temporal Fusion Transformer (TFT)** –º–æ–¥–µ–ª–∏. –ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–∂–∏–¥–∞–µ–º–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –≤ –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–µ.

### üîë –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **Temporal Fusion Transformer**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å attention –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
- **–ú–æ–¥—É–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞**: –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 70% –∫–æ–¥–∞ –∏–∑ XGBoost v3.0
- **–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**: 120 –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ 89 –≥—Ä—É–ø–ø
- **–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**: –ê–Ω–∞–ª–∏–∑ 100 —Å–≤–µ—á–µ–π (25 —á–∞—Å–æ–≤) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
- **Dual-mode**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- **GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: Mixed precision, memory growth

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
transformer_v3/
‚îú‚îÄ‚îÄ config/                  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ settings.py         # Dataclass –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è TFT
‚îÇ   ‚îú‚îÄ‚îÄ features_config.py  # –ì—Ä—É–ø–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (89 —Ç–∏–ø–æ–≤)
‚îÇ   ‚îî‚îÄ‚îÄ constants.py        # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
‚îú‚îÄ‚îÄ data/                   # –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
‚îÇ   ‚îú‚îÄ‚îÄ loader.py          # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineer.py # –°–æ–∑–¥–∞–Ω–∏–µ 120+ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ sequence_creator.py # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ cacher.py         # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ btc_data_loader.py # BTC –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îú‚îÄ‚îÄ models/                 # –ú–æ–¥–µ–ª–∏ TFT
‚îÇ   ‚îú‚îÄ‚îÄ tft_model.py       # Temporal Fusion Transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ tft_trainer.py     # Trainer —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ ensemble.py        # –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã
‚îÇ   ‚îî‚îÄ‚îÄ optimizer.py       # Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
‚îú‚îÄ‚îÄ utils/                  # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ feature_selector.py # –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä (60/20/10/10)
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py         # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py   # –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ report_generator.py # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ logging_manager.py # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îî‚îÄ‚îÄ main.py                # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd transformer_v3
pip install -r requirements.txt
```

### 2. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

```bash
# –†–µ–≥—Ä–µ—Å—Å–∏—è (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –≤ %)
python main.py --task regression

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ profit/loss)
python main.py --task classification_binary

# –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (2 —Å–∏–º–≤–æ–ª–∞, –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ)
python main.py --task regression --test-mode

# –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python main.py --task regression --sequence-length 150 --batch-size 64 --epochs 50
```

### 3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

```bash
# TensorBoard (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
tensorboard --logdir logs/transformer_v3_*/tensorboard/

# –ì—Ä–∞—Ñ–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤:
# logs/transformer_v3_*/plots/
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (config_default.yaml)

```yaml
model:
  hidden_size: 160          # –†–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è
  sequence_length: 100      # –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (25 —á–∞—Å–æ–≤)
  num_heads: 4             # Attention heads
  batch_size: 32           # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
  learning_rate: 0.001     # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
  epochs: 100              # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö

training:
  task_type: "regression"   # regression | classification_binary
  top_k_features: 120      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
  use_data_augmentation: true  # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
```

## üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ TFT

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏

1. **Feature Selection Network**: –û—Ç–±–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
2. **LSTM Encoder-Decoder**: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π  
3. **Self-Attention**: –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –≤–∞–∂–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–∏
4. **Gated Residual Networks (GRN)**: –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å gate –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
5. **Output Layer**: –§–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

### –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

- **–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ**: [batch_size, 100, features] 
- **–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: 100 —Å–≤–µ—á–µ–π –ø–æ 15 –º–∏–Ω—É—Ç = 25 —á–∞—Å–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏
- **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ**: –°–ª–µ–¥—É—é—â–∞—è –æ–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
- **–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è**: –®—É–º + –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–¥–≤–∏–≥–∏ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

## üìä –ü—Ä–∏–∑–Ω–∞–∫–∏ (Feature Engineering)

### –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (120 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)

- **80% –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã**: RSI, MACD, BB, ADX, ATR, Stochastic, Williams %R, MFI, CCI, CMF, OBV, Ichimoku, SAR, Aroon
- **10% BTC –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏**: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å BTC –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö
- **5% –í—Ä–µ–º–µ–Ω–Ω—ã–µ**: –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—á–∞—Å, –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏)
- **5% –ü—Ä–æ—á–∏–µ**: –°–∏–º–≤–æ–ª—ã, –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ—á–µ–π, –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏

### –ì—Ä—É–ø–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

1. **Technical Indicators** (67 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
2. **Market Features** (13 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤) 
3. **OHLC Features** (16 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
4. **Symbol Features** (14 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
5. **Binary Features** (7 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
6. **Engineered Features** (5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
7. **Divergence Features** (3 –ø—Ä–∏–∑–Ω–∞–∫–∞)
8. **Candle Patterns** (2 –ø—Ä–∏–∑–Ω–∞–∫–∞)
9. **Volume Profile** (1 –ø—Ä–∏–∑–Ω–∞–∫)

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –†–µ–≥—Ä–µ—Å—Å–∏—è
- **MAE**: Mean Absolute Error
- **MSE**: Mean Squared Error  
- **R¬≤**: Coefficient of determination
- **Directional Accuracy**: –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π

### –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
- **Accuracy**: –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
- **Precision/Recall**: –¢–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç–∞
- **F1-Score**: –ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
- **ROC-AUC**: Area Under Curve

## üîß –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### 1. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
use_data_augmentation: true
augmentation_noise_level: 0.01    # 1% —à—É–º
augmentation_shift_range: 2       # ¬±2 timestep —Å–¥–≤–∏–≥–∏
```

### 2. Mixed Precision (GPU)
```python
# –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ GPU
use_mixed_precision: true
memory_growth: true
```

### 3. Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
use_optuna: true
optuna_trials: 50
```

### 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- –ì—Ä–∞—Ñ–∏–∫–∏ loss/accuracy –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∫–∞–∂–¥—ã–µ 5 —ç–ø–æ—Ö
- TensorBoard –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
- Attention weights –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏

## üéØ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å XGBoost v3.0

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | XGBoost v3.0 | Transformer v3.0 |
|-----------|--------------|------------------|
| **–ú–æ–¥–µ–ª—å** | Gradient Boosting | Temporal Fusion Transformer |
| **–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ** | –¢–∞–±–ª–∏—á–Ω—ã–µ | –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ |
| **–ü–∞–º—è—Ç—å** | ~2GB | ~8GB (GPU) |
| **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è** | 20-30 –º–∏–Ω | 2-4 —á–∞—Å–∞ |
| **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** | Feature importance | Attention weights |
| **–ö–∞—á–µ—Å—Ç–≤–æ** | –í—ã—Å–æ–∫–æ–µ | –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤—ã—à–µ |

## üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–æ–≥–æ–≤
```
logs/transformer_v3_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ training.log              # –ü–æ–ª–Ω—ã–π –ª–æ–≥ –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ config.yaml               # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ buy_models/               # –ú–æ–¥–µ–ª–∏ –¥–ª—è buy –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ buy_predictor/        # SavedModel —Ñ–æ—Ä–º–∞—Ç
‚îÇ   ‚îú‚îÄ‚îÄ buy_predictor_weights.h5  # –í–µ—Å–∞ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ buy_predictor_metadata.json  # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
‚îú‚îÄ‚îÄ sell_models/              # –ú–æ–¥–µ–ª–∏ –¥–ª—è sell –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
‚îú‚îÄ‚îÄ plots/                    # –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ *_training_history.png    # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ *_progress_epoch_*.png     # –ü—Ä–æ–≥—Ä–µ—Å—Å –ø–æ —ç–ø–æ—Ö–∞–º
‚îÇ   ‚îî‚îÄ‚îÄ sequence_info.json         # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö
‚îú‚îÄ‚îÄ tensorboard/              # TensorBoard –ª–æ–≥–∏
‚îî‚îÄ‚îÄ final_report.txt          # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
```

## üêõ –û—Ç–ª–∞–¥–∫–∞ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

1. **Out of Memory (GPU)**
```python
# –£–º–µ–Ω—å—à–∏—Ç–µ batch_size
batch_size: 16  # –≤–º–µ—Å—Ç–æ 32

# –ò–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ sequence_length
sequence_length: 50  # –≤–º–µ—Å—Ç–æ 100
```

2. **–ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
```python
# –í–∫–ª—é—á–∏—Ç–µ mixed precision
use_mixed_precision: true

# –£–≤–µ–ª–∏—á—å—Ç–µ batch_size (–µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å)
batch_size: 64
```

3. **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**
```python
# –£–≤–µ–ª–∏—á—å—Ç–µ dropout
dropout_rate: 0.2  # –≤–º–µ—Å—Ç–æ 0.1

# –î–æ–±–∞–≤—å—Ç–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é
l2_regularization: 0.02
```

## üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å XGBoost v3.0

Transformer v3.0 –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º —Å pipeline XGBoost v3.0:

1. **–û–±—â–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö**: PostgreSQL –Ω–∞ –ø–æ—Ä—Ç—É 5555
2. **–û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**: Feature engineering –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
3. **–°—Ä–∞–≤–Ω–∏–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**: –ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫  
4. **–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ú–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å XGBoost + TFT –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Temporal Fusion Transformer Paper](https://arxiv.org/abs/1912.09363)
- [TensorFlow Time Series Guide](https://www.tensorflow.org/tutorials/structured_data/time_series)
- [XGBoost v3.0 Documentation](../xgboost_v3/README.md)

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

1. Fork —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ feature branch: `git checkout -b feature/amazing-feature`
3. Commit –∏–∑–º–µ–Ω–µ–Ω–∏—è: `git commit -m 'Add amazing feature'`
4. Push –≤ branch: `git push origin feature/amazing-feature`
5. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

Distributed under the MIT License. See `LICENSE` for more information.