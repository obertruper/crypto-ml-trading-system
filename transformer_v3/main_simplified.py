#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π main –¥–ª—è Transformer v3 —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import argparse
import logging
import warnings
from datetime import datetime
from pathlib import Path
import numpy as np
import pandas as pd
import tensorflow as tf

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from transformer_v3.config import Config
from transformer_v3.data.loader import DataLoader
from transformer_v3.data.data_processor import DataProcessor
from transformer_v3.data.noise_filter import NoiseFilter
from transformer_v3.data.sequence_creator import SequenceCreator
from transformer_v3.data.cacher import CacheManager
from transformer_v3.models.ensemble import TFTEnsemble
from transformer_v3.utils.logging_manager import LoggingManager
from transformer_v3.utils.report_generator import ReportGenerator

# –ü–æ–¥–∞–≤–ª—è–µ–º –Ω–µ–∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ TensorFlow
tf.config.optimizer.set_jit(False)  # –û—Ç–∫–ª—é—á–∞–µ–º XLA –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
tf.get_logger().setLevel('ERROR')

logger = logging.getLogger(__name__)


def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='Transformer v3.0 - ML Trading (Simplified)')
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--task', type=str, default='regression',
                       choices=['regression', 'classification_binary'],
                       help='–¢–∏–ø –∑–∞–¥–∞—á–∏')
    parser.add_argument('--test-mode', action='store_true',
                       help='–¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (—Ç–æ–ª—å–∫–æ 2 —Å–∏–º–≤–æ–ª–∞)')
    parser.add_argument('--test-symbols', nargs='+', 
                       default=['BTCUSDT', 'ETHUSDT'],
                       help='–°–∏–º–≤–æ–ª—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--batch-size', type=int, default=None,
                       help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)')
    parser.add_argument('--learning-rate', type=float, default=None,
                       help='Learning rate (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)')
    parser.add_argument('--epochs', type=int, default=None,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)')
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
    parser.add_argument('--no-mixed-precision', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å mixed precision')
    parser.add_argument('--gradient-clip', type=float, default=1.0,
                       help='Gradient clipping threshold')
    
    # –î—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--no-cache', action='store_true',
                       help='–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à')
    parser.add_argument('--config', type=str, default='config.yaml',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    
    return parser.parse_args()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    args = parse_arguments()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_path = Path(args.config) if args.config else None
    if config_path and config_path.exists():
        config = Config.from_yaml(str(config_path))
    else:
        config = Config()
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if args.task:
        config.training.task_type = args.task
    if args.batch_size:
        config.training.batch_size = args.batch_size
    if args.learning_rate:
        config.training.learning_rate = args.learning_rate
    if args.epochs:
        config.training.epochs = args.epochs
    if args.no_mixed_precision:
        config.model.use_mixed_precision = False
        
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config.validate()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    log_dir = config.get_log_dir()
    logging_manager = LoggingManager(log_dir)
    logging_manager.setup_logging()
    
    logger.info("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë   Transformer v3.0 - Simplified Trading  ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    logger.info(f"üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    logger.info(f"   Task: {config.training.task_type}")
    logger.info(f"   Batch size: {config.training.batch_size}")
    logger.info(f"   Learning rate: {config.training.learning_rate}")
    logger.info(f"   Optimizer: {config.training.optimizer}")
    logger.info(f"   Test mode: {args.test_mode}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config.save(log_dir / "config.yaml")
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        logger.info("\n" + "="*60)
        logger.info("üì• –®–ê–ì 1: –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        cacher = CacheManager(config)
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫—ç—à–∞
        df = None
        if not args.no_cache:
            df = cacher.load_processed_data('processed')
            if df is not None:
                logger.info("üìÇ –ò—Å–ø–æ–ª—å–∑—É—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        
        if df is None:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
            raw_df = cacher.load_processed_data('raw')
            if raw_df is None:
                with DataLoader(config) as data_loader:
                    if args.test_mode:
                        raw_df = data_loader.load_data(symbols=args.test_symbols, limit=50000)
                    else:
                        raw_df = data_loader.load_data()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
                if not args.test_mode:
                    cacher.save_processed_data(raw_df, 'raw')
            
            # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            logger.info("\n" + "="*60)
            logger.info("üîß –®–ê–ì 2: –£–ü–†–û–©–ï–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•")
            logger.info("="*60)
            
            processor = DataProcessor(config)
            df = processor.process_data(raw_df)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —à—É–º–∞
            logger.info("üîá –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —à—É–º–∞...")
            noise_filter = NoiseFilter(method='ensemble')
            
            numeric_cols = [col for col in df.columns 
                          if col not in ['timestamp', 'buy_expected_return', 'sell_expected_return']]
            
            for col in numeric_cols:
                if df[col].std() > 0:
                    df[col] = noise_filter.filter_series(df[col].values)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if not args.test_mode:
                cacher.save_processed_data(df, 'processed')
        
        # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        logger.info("\n" + "="*60)
        logger.info("‚úÇÔ∏è –®–ê–ì 3: –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        processor = DataProcessor(config)
        processor.feature_columns = [col for col in df.columns 
                                   if col not in ['timestamp', 'buy_expected_return', 'sell_expected_return']]
        
        data_splits = processor.split_data(df)
        
        logger.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(processor.feature_columns)}")
        logger.info(f"üìä –¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {processor.feature_columns[:10]}")
        
        # 4. –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        logger.info("\n" + "="*60)
        logger.info("üîÑ –®–ê–ì 4: –°–û–ó–î–ê–ù–ò–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô")
        logger.info("="*60)
        
        sequence_creator = SequenceCreator(config)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        for direction in ['buy', 'sell']:
            logger.info(f"\n{'='*60}")
            logger.info(f"üéØ –û–ë–†–ê–ë–û–¢–ö–ê –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø: {direction.upper()}")
            logger.info(f"{'='*60}")
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            target_col = f'{direction}_expected_return'
            
            X_train_seq, y_train_seq = sequence_creator.create_sequences(
                data_splits[direction]['X_train'],
                data_splits[direction]['y_train'],
                target_column=target_col
            )
            
            X_val_seq, y_val_seq = sequence_creator.create_sequences(
                data_splits[direction]['X_val'],
                data_splits[direction]['y_val'],
                target_column=target_col
            )
            
            X_test_seq, y_test_seq = sequence_creator.create_sequences(
                data_splits[direction]['X_test'],
                data_splits[direction]['y_test'],
                target_column=target_col
            )
            
            logger.info(f"üìä –†–∞–∑–º–µ—Ä—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π:")
            logger.info(f"   Train: {X_train_seq.shape}")
            logger.info(f"   Val: {X_val_seq.shape}")
            logger.info(f"   Test: {X_test_seq.shape}")
            
            # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            logger.info("\n" + "="*60)
            logger.info(f"üöÄ –®–ê–ì 5: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô ({direction})")
            logger.info("="*60)
            
            # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å
            ensemble = TFTEnsemble(
                config=config,
                model_name=f"tft_{direction}_model",
                n_models=3  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
            )
            
            # –û–±—É—á–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å
            ensemble.train_ensemble(
                X_train_seq, y_train_seq,
                X_val_seq, y_val_seq,
                feature_columns=processor.feature_columns
            )
            
            # 6. –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
            logger.info("\n" + "="*60)
            logger.info("üìä –®–ê–ì 6: –û–¶–ï–ù–ö–ê –ù–ê –¢–ï–°–¢–û–í–û–ô –í–´–ë–û–†–ö–ï")
            logger.info("="*60)
            
            test_metrics = ensemble.evaluate(X_test_seq, y_test_seq, "Test")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏
            save_dir = log_dir / f"models_{direction}"
            ensemble.save_models(save_dir)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            report_gen = ReportGenerator(log_dir)
            report_gen.generate_model_report(
                model_name=f"ensemble_{direction}",
                metrics={
                    'train': ensemble.train_metrics,
                    'val': ensemble.val_metrics,
                    'test': test_metrics
                },
                config=config,
                feature_importance=ensemble.get_feature_importance()
            )
        
        logger.info("\n" + "="*60)
        logger.info("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        logger.info("="*60)
        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {log_dir}")
        
    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\n‚ùå –û—à–∏–±–∫–∞: {str(e)}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()