"""
–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ TFT –º–æ–¥–µ–ª–µ–π
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import logging
from typing import List, Dict, Optional
from pathlib import Path

from config import Config
from models.tft_trainer import TFTTrainer

logger = logging.getLogger(__name__)


class TFTEnsemble:
    """–ê–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö TFT –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, config: Config, base_name: str = "tft"):
        self.config = config
        self.base_name = base_name
        self.models = []
        self.trainers = []
        self.weights = None
        
    def train_ensemble(self,
                      X_train: np.ndarray,
                      y_train: np.ndarray,
                      X_val: np.ndarray,
                      y_val: np.ndarray,
                      n_models: int = 3,
                      feature_columns: List[str] = None) -> List[keras.Model]:
        """
        –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π
        
        Args:
            X_train: –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            y_train: –û–±—É—á–∞—é—â–∏–µ –º–µ—Ç–∫–∏
            X_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            y_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            n_models: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤ –∞–Ω—Å–∞–º–±–ª–µ
            feature_columns: –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"üéØ –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∏–∑ {n_models} –º–æ–¥–µ–ª–µ–π")
        logger.info(f"{'='*60}")
        
        self.models = []
        self.trainers = []
        val_scores = []
        
        for i in range(n_models):
            logger.info(f"\nüìä –ú–æ–¥–µ–ª—å {i+1}/{n_models}")
            
            # –°–æ–∑–¥–∞–µ–º trainer —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
            model_name = f"{self.base_name}_model_{i+1}"
            trainer = TFTTrainer(self.config, model_name=model_name)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            # 1. Bootstrap sampling
            if i > 0:  # –ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                indices = np.random.choice(len(X_train), size=len(X_train), replace=True)
                X_train_boot = X_train[indices]
                y_train_boot = y_train[indices]
            else:
                X_train_boot = X_train
                y_train_boot = y_train
            
            # 2. –†–∞–∑–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (—á–µ—Ä–µ–∑ seed)
            tf.random.set_seed(42 + i)
            np.random.seed(42 + i)
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model = trainer.train(
                X_train_boot, y_train_boot,
                X_val, y_val,
                feature_columns=feature_columns
            )
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            val_metrics = trainer.evaluate(X_val, y_val, f"Validation (Model {i+1})")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º score –¥–ª—è –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è
            if self.config.training.task_type == 'regression':
                val_score = -val_metrics['mae']  # –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º MAE
            else:
                val_score = val_metrics['accuracy']  # –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º accuracy
                
            val_scores.append(val_score)
            
            self.models.append(model)
            self.trainers.append(trainer)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –¥–ª—è –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
        self._calculate_weights(val_scores)
        
        logger.info(f"\n‚úÖ –ê–Ω—Å–∞–º–±–ª—å –æ–±—É—á–µ–Ω. –í–µ—Å–∞ –º–æ–¥–µ–ª–µ–π: {self.weights}")
        
        return self.models
    
    def _calculate_weights(self, scores: List[float]):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        scores = np.array(scores)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º scores –≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
        min_score = scores.min()
        if min_score < 0:
            scores = scores - min_score
        
        # Softmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Å–æ–≤
        exp_scores = np.exp(scores)
        self.weights = exp_scores / exp_scores.sum()
    
    def predict(self, X: np.ndarray, return_proba: bool = False) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
        
        Args:
            X: –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            return_proba: –í–µ—Ä–Ω—É—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            
        Returns:
            –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        if not self.models:
            raise ValueError("–ê–Ω—Å–∞–º–±–ª—å –Ω–µ –æ–±—É—á–µ–Ω")
        
        predictions = []
        
        for i, model in enumerate(self.models):
            pred = model.predict(X, verbose=0)
            predictions.append(pred.flatten())
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
        predictions = np.array(predictions)
        
        if self.weights is not None:
            ensemble_pred = np.average(predictions, axis=0, weights=self.weights)
        else:
            ensemble_pred = np.mean(predictions, axis=0)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if self.config.training.task_type == "classification_binary" and not return_proba:
            threshold = self.config.training.classification_threshold / 100
            ensemble_pred = (ensemble_pred > threshold).astype(int)
        
        return ensemble_pred
    
    def evaluate(self, X: np.ndarray, y: np.ndarray, dataset_name: str = "Test") -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ –∞–Ω—Å–∞–º–±–ª—è"""
        predictions = self.predict(X, return_proba=True)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç –ø–µ—Ä–≤–æ–≥–æ trainer
        if self.trainers:
            metrics = self.trainers[0].metrics_calculator.calculate_metrics(
                y, predictions, 
                task_type=self.config.training.task_type
            )
        else:
            metrics = {}
        
        logger.info(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ {dataset_name}:")
        for metric_name, value in metrics.items():
            if isinstance(value, (int, float)):
                logger.info(f"   {metric_name}: {value:.4f}")
        
        return metrics
    
    def save_ensemble(self, save_dir: Path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª—è"""
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –≤ {save_dir}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
        for i, trainer in enumerate(self.trainers):
            model_dir = save_dir / f"model_{i+1}"
            trainer.save_model(model_dir)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω—Å–∞–º–±–ª—è
        ensemble_meta = {
            'n_models': len(self.models),
            'weights': self.weights.tolist() if self.weights is not None else None,
            'base_name': self.base_name,
            'task_type': self.config.training.task_type
        }
        
        import json
        with open(save_dir / "ensemble_metadata.json", 'w') as f:
            json.dump(ensemble_meta, f, indent=2)
        
        logger.info("‚úÖ –ê–Ω—Å–∞–º–±–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
    
    def load_ensemble(self, load_dir: Path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω—Å–∞–º–±–ª—è"""
        load_dir = Path(load_dir)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        import json
        with open(load_dir / "ensemble_metadata.json", 'r') as f:
            meta = json.load(f)
        
        self.weights = np.array(meta['weights']) if meta['weights'] else None
        n_models = meta['n_models']
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
        self.models = []
        self.trainers = []
        
        for i in range(n_models):
            model_dir = load_dir / f"model_{i+1}"
            model_path = model_dir / f"{self.base_name}_model_{i+1}.h5"
            
            trainer = TFTTrainer(self.config, model_name=f"{self.base_name}_model_{i+1}")
            trainer.load_model(model_path)
            
            self.models.append(trainer.model)
            self.trainers.append(trainer)
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –∞–Ω—Å–∞–º–±–ª—å –∏–∑ {n_models} –º–æ–¥–µ–ª–µ–π")