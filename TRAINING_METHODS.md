# üéØ –ú–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

## üìä –û–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –æ–±—É—á–µ–Ω–∏—è

### 1. Temporal Fusion Transformer (TFT) - –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥

**–û–ø–∏—Å–∞–Ω–∏–µ**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, –∫–æ–º–±–∏–Ω–∏—Ä—É—é—â–∞—è LSTM, Attention –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å —á–µ—Ä–µ–∑ attention –≤–µ—Å–∞

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
```python
def create_temporal_fusion_transformer(input_shape):
    # 1. Variable Selection Network
    vsn_weights = Dense(n_features, activation='softmax')
    selected_features = Multiply()([inputs, vsn_weights])
    
    # 2. Temporal Processing
    lstm_out = LSTM(128, return_sequences=True, dropout=0.2)
    lstm_out = LSTM(64, return_sequences=True, dropout=0.2)
    
    # 3. Self-Attention
    attention = MultiHeadAttention(num_heads=4, key_dim=16)
    
    # 4. Feed Forward
    ff_out = Dense(128, activation='relu')
    ff_out = Dense(64)
    
    # 5. Output
    output = Dense(1, activation='sigmoid')
```

### 2. –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è LSTM –º–æ–¥–µ–ª—å (–∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**: –ü—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö —Å –æ–±—É—á–µ–Ω–∏–µ–º TFT

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
```python
def create_simple_model(input_shape):
    x = LSTM(64, return_sequences=True, dropout=0.2)
    x = LSTM(32, dropout=0.2)
    x = Dense(32, activation='relu')
    x = Dropout(0.3)
    x = Dense(16, activation='relu')
    x = Dropout(0.2)
    output = Dense(1, activation='sigmoid')
```

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

### –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (config.yaml)

```yaml
model:
  # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö
  sequence_length: 60        # –î–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                            # 60 = 15 —á–∞—Å–æ–≤ –¥–ª—è 15m —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
                            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: 40-100
  
  prediction_horizon: 100    # –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
                            # 100 = 25 —á–∞—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ SL/TP
                            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: 50-200
  
  # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
  batch_size: 32            # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
                           # –ú–µ–Ω—å—à–µ = –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ
                           # –ë–æ–ª—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏
                           # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: 16-64
  
  epochs: 100              # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
                          # –° EarlyStopping –æ–±—ã—á–Ω–æ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –Ω–∞ 30-50
                          # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: 50-200
  
  learning_rate: 0.001     # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
                          # –ù–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –¥–ª—è Adam optimizer
                          # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: 0.0001-0.01
```

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∫–æ–¥–µ

```python
# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
optimizer = Adam(
    learning_rate=0.001,
    clipnorm=1.0,          # Gradient clipping –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    beta_1=0.9,            # –ú–æ–º–µ–Ω—Ç –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    beta_2=0.999,          # –ú–æ–º–µ–Ω—Ç –¥–ª—è –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    epsilon=1e-7           # –î–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
)

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
loss = 'binary_crossentropy'  # –î–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:
# - 'focal_loss' - –ª—É—á—à–µ –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
# - 'weighted_binary_crossentropy' - —Å –≤–µ—Å–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤

# –ú–µ—Ç—Ä–∏–∫–∏
metrics = [
    'accuracy',            # –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
    'precision',           # –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    'recall',              # –ü–æ–ª–Ω–æ—Ç–∞ (–ø—Ä–æ—Ü–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö)
    tf.keras.metrics.AUC() # –ü–ª–æ—â–∞–¥—å –ø–æ–¥ ROC –∫—Ä–∏–≤–æ–π
]
```

### Callbacks (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)

```python
# 1. Early Stopping - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π
EarlyStopping(
    monitor='val_loss',       # –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    patience=15,              # –≠–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è –¥–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    restore_best_weights=True # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª—É—á—à–∏–µ –≤–µ—Å–∞
)

# 2. Reduce Learning Rate - —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
ReduceLROnPlateau(
    monitor='val_loss',    # –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    factor=0.5,           # –í–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —É–º–µ–Ω—å—à–∞—Ç—å LR
    patience=8,           # –≠–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è
    min_lr=1e-6          # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
)

# 3. Model Checkpoint - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
ModelCheckpoint(
    filepath='models/{model_name}_best.h5',
    monitor='val_loss',
    save_best_only=True
)
```

### –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤
pos_samples = sum(y_train)
neg_samples = len(y_train) - pos_samples
class_weight = {
    0: 1.0,
    1: neg_samples / pos_samples  # –ë–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è —Ä–µ–¥–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞
}

# –ü—Ä–∏–º–µ—Ä –¥–ª—è –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö:
# BUY signals: 8.1% positive -> weight = 11.3
# SELL signals: 15.6% positive -> weight = 5.4
```

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –î–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:

1. **–ü—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏** (val_loss —Ä–∞—Å—Ç–µ—Ç, train_loss –ø–∞–¥–∞–µ—Ç):
   - –£–≤–µ–ª–∏—á–∏—Ç—å dropout: 0.2 ‚Üí 0.3-0.5
   - –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (–º–µ–Ω—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤)
   - –£–≤–µ–ª–∏—á–∏—Ç—å patience –≤ EarlyStopping
   - –î–æ–±–∞–≤–∏—Ç—å L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é

2. **–ü—Ä–∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏–∏** (–æ–±–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–ª–æ—Ö–∏–µ):
   - –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
   - –£–≤–µ–ª–∏—á–∏—Ç—å epochs
   - –£–≤–µ–ª–∏—á–∏—Ç—å learning_rate
   - –£–º–µ–Ω—å—à–∏—Ç—å dropout

3. **–ü—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ –∫–ª–∞—Å—Å–æ–≤**:
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å focal loss
   - –£–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Å–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SMOTE –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤
   - –ò–∑–º–µ–Ω–∏—Ç—å threshold (–≤–º–µ—Å—Ç–æ 0.5)

### –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è:

1. **–£–≤–µ–ª–∏—á–∏—Ç—å batch_size** (–µ—Å–ª–∏ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏)
2. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å mixed precision training**:
   ```python
   policy = tf.keras.mixed_precision.Policy('mixed_float16')
   tf.keras.mixed_precision.set_global_policy(policy)
   ```

3. **–£–º–µ–Ω—å—à–∏—Ç—å sequence_length** (–Ω–æ –Ω–µ –º–µ–Ω—å—à–µ 40)

### –î–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π —Ä—ã–Ω–∫–∞:

1. **–í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å**:
   - –£–º–µ–Ω—å—à–∏—Ç—å prediction_horizon (50-75)
   - –£–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Å–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

2. **–ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å**:
   - –£–≤–µ–ª–∏—á–∏—Ç—å prediction_horizon (100-150)
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
   - –£–º–µ–Ω—å—à–∏—Ç—å learning_rate

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è:

1. **Loss** - –æ—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
   - –î–æ–ª–∂–Ω–∞ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è
   - val_loss –Ω–µ –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏

2. **Accuracy** - –æ–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
   - –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: >65%
   - –ù–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–º–∞–Ω—á–∏–≤–∞ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ

3. **Precision/Recall** - –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
   - Precision: –∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö positive —Å–∫–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö
   - Recall: –∏–∑ –≤—Å–µ—Ö positive —Å–∫–æ–ª—å–∫–æ –Ω–∞—à–ª–∏

4. **AUC** - –∏–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
   - >0.7 - —Ö–æ—Ä–æ—à–æ
   - >0.8 - –æ—Ç–ª–∏—á–Ω–æ

### –ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è:

1. **NaN –≤ loss**:
   - –£–º–µ–Ω—å—à–∏—Ç—å learning_rate
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ inf/nan
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å gradient clipping

2. **–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ —É–ª—É—á—à–∞—é—Ç—Å—è**:
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
   - –ò–∑–º–µ–Ω–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
   - –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

3. **–û—á–µ–Ω—å –¥–æ–ª–≥–æ–µ –æ–±—É—á–µ–Ω–∏–µ**:
   - –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU
   - –£–º–µ–Ω—å—à–∏—Ç—å batch_size

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –î–ª—è –Ω–∞—á–∞–ª–∞ (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ):
```yaml
sequence_length: 40
batch_size: 64
epochs: 30
learning_rate: 0.001
```

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:
```yaml
sequence_length: 60-80
batch_size: 32
epochs: 100
learning_rate: 0.0005
```

### –î–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π:
```yaml
sequence_length: 100-120
batch_size: 16
epochs: 200
learning_rate: 0.0001
```