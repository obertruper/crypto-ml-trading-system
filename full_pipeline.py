#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
"""

import yaml
import logging
import time
from datetime import datetime
from download_data import PostgreSQLManager, BybitDataDownloader
from prepare_dataset import MarketDatasetPreparator
from train_model_postgres import MarketMovementPredictor

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def check_symbol_support(downloader, symbols):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è API"""
    supported = []
    unsupported = []
    
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å–∏–º–≤–æ–ª–æ–≤...")
    
    for symbol in symbols:
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å 1 —Å–≤–µ—á—É
            klines = downloader.get_klines(symbol, '15', 
                                          int(time.time() * 1000) - 900000,  # 15 –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥
                                          int(time.time() * 1000))
            if klines:
                supported.append(symbol)
                logger.info(f"‚úÖ {symbol} - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
            else:
                unsupported.append(symbol)
                logger.warning(f"‚ùå {symbol} - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
        except Exception as e:
            unsupported.append(symbol)
            logger.warning(f"‚ùå {symbol} - –æ—à–∏–±–∫–∞: {str(e)}")
        
        time.sleep(0.1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    return supported, unsupported


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    db_config = config['database']
    data_config = config['data_download']
    model_config = config['model']
    risk_profile = config['risk_profile']
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    db_manager = PostgreSQLManager(db_config)
    
    try:
        db_manager.connect()
        
        # –®–ê–ì 1: –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
        logger.info("\n" + "="*60)
        logger.info("–®–ê–ì 1: –ó–ê–ì–†–£–ó–ö–ê –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        downloader = BybitDataDownloader(db_manager)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Å–∏–º–≤–æ–ª—ã
        all_symbols = data_config['symbols']
        supported_symbols, unsupported_symbols = check_symbol_support(downloader, all_symbols)
        
        logger.info(f"\nüìä –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: {len(supported_symbols)}/{len(all_symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        if unsupported_symbols:
            logger.warning(f"‚ö†Ô∏è –ù–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: {', '.join(unsupported_symbols)}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º config.yaml —Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
            config['data_download']['symbols'] = supported_symbols
            config['data_download']['unsupported_symbols'] = unsupported_symbols
            
            with open('config_updated.yaml', 'w') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥: config_updated.yaml")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        if supported_symbols:
            interval = data_config['interval']
            days = data_config['days']
            
            logger.info(f"\nüöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(supported_symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: –∏–Ω—Ç–µ—Ä–≤–∞–ª={interval}m, –ø–µ—Ä–∏–æ–¥={days} –¥–Ω–µ–π")
            
            results = downloader.download_multiple_symbols(supported_symbols, interval, days)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏
            success_count = sum(1 for r in results.values() if r.get('success', False))
            logger.info(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {success_count}/{len(supported_symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –®–ê–ì 2: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê
        logger.info("\n" + "="*60)
        logger.info("–®–ê–ì 2: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê")
        logger.info("="*60)
        
        preparator = MarketDatasetPreparator(db_manager, risk_profile)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏
        symbols_with_data = preparator.get_available_symbols()
        
        if not symbols_with_data:
            logger.error("‚ùå –ù–µ—Ç —Å–∏–º–≤–æ–ª–æ–≤ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö!")
            return
        
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(symbols_with_data)} —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Å–∏–º–≤–æ–ª
        total_processed = 0
        for symbol in symbols_with_data:
            try:
                logger.info(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {symbol}...")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
                df = preparator.load_raw_data(symbol)
                
                if len(df) < 100:
                    logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
                    continue
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                indicators = preparator.calculate_technical_indicators(df)
                
                # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏
                labels = preparator.create_labels_based_on_risk_profile(df, symbol)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                preparator.save_processed_data(symbol, df, indicators, labels)
                
                total_processed += 1
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                if total_processed == 1:
                    preparator.save_feature_columns_metadata(list(indicators.keys()))
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {symbol}: {e}")
                continue
        
        logger.info(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_processed} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –®–ê–ì 3: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò
        logger.info("\n" + "="*60)
        logger.info("–®–ê–ì 3: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
        logger.info("="*60)
        
        if total_processed == 0:
            logger.error("‚ùå –ù–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
            return
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä
        predictor = MarketMovementPredictor(
            db_manager=db_manager,
            sequence_length=model_config['sequence_length'],
            prediction_horizon=model_config['prediction_horizon']
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        predictor.load_feature_columns()
        
        if not predictor.feature_columns:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!")
            return
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(predictor.feature_columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –ë–î
        logger.info("\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        training_data = predictor.create_sequences_from_db()
        
        if not training_data:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏!")
            return
        
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(training_data['X_sequences'])} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        
        # –û–±—É—á–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
        logger.info("\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
        training_results = predictor.train_all_models(training_data)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        performance_summary = predictor.evaluate_model_performance(training_results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        predictor.save_complete_model(training_results, training_data)
        
        logger.info("\n" + "="*60)
        logger.info("üéâ –ü–ê–ô–ü–õ–ê–ô–ù –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        logger.info("="*60)
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {success_count}")
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {total_processed}")
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: 4")
        logger.info(f"üíæ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: trained_model/")
        logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫–∏ –≤: plots/")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î
        stats = downloader.get_database_stats()
        total_records = sum(s['total_records'] for s in stats.values())
        logger.info(f"\nüìä –ò–¢–û–ì–û –í –ë–î: {total_records:,} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {len(stats)} —Å–∏–º–≤–æ–ª–æ–≤")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise
    finally:
        db_manager.disconnect()


if __name__ == "__main__":
    main()