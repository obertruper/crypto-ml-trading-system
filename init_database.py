#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL
–°–æ–∑–¥–∞–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞
"""

import psycopg2
import yaml
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_config(config_path: str = "config.yaml") -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞"""
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        raise


def create_database(db_config: dict):
    """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ postgres –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
    conn_params = db_config.copy()
    database_name = conn_params.pop('dbname')
    conn_params['dbname'] = 'postgres'
    
    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç–æ–π –ø–∞—Ä–æ–ª—å
    if not conn_params.get('password'):
        conn_params.pop('password', None)
    
    try:
        conn = psycopg2.connect(**conn_params)
        conn.autocommit = True
        cursor = conn.cursor()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ë–î
        cursor.execute(
            "SELECT 1 FROM pg_database WHERE datname = %s",
            (database_name,)
        )
        
        if not cursor.fetchone():
            cursor.execute(f"CREATE DATABASE {database_name}")
            logger.info(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö '{database_name}' —Å–æ–∑–¥–∞–Ω–∞")
        else:
            logger.info(f"‚ÑπÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö '{database_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise


def init_tables(db_config: dict):
    """–°–æ–∑–¥–∞–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ç–∞–±–ª–∏—Ü—ã"""
    
    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç–æ–π –ø–∞—Ä–æ–ª—å
    conn_params = db_config.copy()
    if not conn_params.get('password'):
        conn_params.pop('password', None)
    
    try:
        conn = psycopg2.connect(**conn_params)
        conn.autocommit = True
        cursor = conn.cursor()
        
        logger.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –≤ PostgreSQL...")
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—ã—Ä—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        create_raw_data_table = """
        CREATE TABLE IF NOT EXISTS raw_market_data (
            id BIGSERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            timestamp BIGINT NOT NULL,
            datetime TIMESTAMP NOT NULL,
            open DECIMAL(20, 8) NOT NULL,
            high DECIMAL(20, 8) NOT NULL,
            low DECIMAL(20, 8) NOT NULL,
            close DECIMAL(20, 8) NOT NULL,
            volume DECIMAL(20, 8) NOT NULL,
            turnover DECIMAL(20, 8) DEFAULT 0,
            interval_minutes INTEGER NOT NULL DEFAULT 15,
            created_at TIMESTAMP DEFAULT NOW(),
            UNIQUE(symbol, timestamp, interval_minutes)
        );
        """
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        create_indexes = """
        CREATE INDEX IF NOT EXISTS idx_raw_market_data_symbol_timestamp 
        ON raw_market_data(symbol, timestamp);
        
        CREATE INDEX IF NOT EXISTS idx_raw_market_data_datetime 
        ON raw_market_data(datetime);
        
        CREATE INDEX IF NOT EXISTS idx_raw_market_data_symbol_datetime 
        ON raw_market_data(symbol, datetime);
        """
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
        create_processed_data_table = """
        CREATE TABLE IF NOT EXISTS processed_market_data (
            id BIGSERIAL PRIMARY KEY,
            raw_data_id BIGINT REFERENCES raw_market_data(id),
            symbol VARCHAR(20) NOT NULL,
            timestamp BIGINT NOT NULL,
            datetime TIMESTAMP NOT NULL,
            
            -- –ë–∞–∑–æ–≤—ã–µ OHLCV
            open DECIMAL(20, 8) NOT NULL,
            high DECIMAL(20, 8) NOT NULL,
            low DECIMAL(20, 8) NOT NULL,
            close DECIMAL(20, 8) NOT NULL,
            volume DECIMAL(20, 8) NOT NULL,
            
            -- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (JSON –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏)
            technical_indicators JSONB,
            
            -- –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–º–µ—Ç–∫–∏)
            buy_profit_target INTEGER DEFAULT 0,
            buy_loss_target INTEGER DEFAULT 0,
            sell_profit_target INTEGER DEFAULT 0,
            sell_loss_target INTEGER DEFAULT 0,
            
            -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            processing_version VARCHAR(10) DEFAULT '1.0',
            created_at TIMESTAMP DEFAULT NOW(),
            updated_at TIMESTAMP DEFAULT NOW(),
            
            UNIQUE(symbol, timestamp)
        );
        """
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è processed_data
        create_processed_indexes = """
        CREATE INDEX IF NOT EXISTS idx_processed_market_data_symbol_timestamp 
        ON processed_market_data(symbol, timestamp);
        
        CREATE INDEX IF NOT EXISTS idx_processed_market_data_targets 
        ON processed_market_data(buy_profit_target, buy_loss_target, sell_profit_target, sell_loss_target);
        
        CREATE INDEX IF NOT EXISTS idx_processed_technical_indicators 
        ON processed_market_data USING GIN (technical_indicators);
        """
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
        create_model_metadata_table = """
        CREATE TABLE IF NOT EXISTS model_metadata (
            id SERIAL PRIMARY KEY,
            model_name VARCHAR(100) NOT NULL,
            model_type VARCHAR(50) NOT NULL,
            version VARCHAR(20) NOT NULL,
            feature_columns JSONB,
            training_config JSONB,
            performance_metrics JSONB,
            file_path VARCHAR(500),
            created_at TIMESTAMP DEFAULT NOW(),
            is_active BOOLEAN DEFAULT TRUE
        );
        """
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        create_sequences_table = """
        CREATE TABLE IF NOT EXISTS training_sequences (
            id BIGSERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            sequence_start_timestamp BIGINT NOT NULL,
            sequence_end_timestamp BIGINT NOT NULL,
            sequence_length INTEGER NOT NULL,
            features JSONB NOT NULL,
            buy_profit_target INTEGER DEFAULT 0,
            buy_loss_target INTEGER DEFAULT 0,
            sell_profit_target INTEGER DEFAULT 0,
            sell_loss_target INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT NOW()
        );
        """
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        create_predictions_table = """
        CREATE TABLE IF NOT EXISTS model_predictions (
            id BIGSERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            timestamp BIGINT NOT NULL,
            datetime TIMESTAMP NOT NULL,
            model_version VARCHAR(20) NOT NULL,
            
            -- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            buy_profit_probability DECIMAL(5, 4),
            buy_loss_probability DECIMAL(5, 4),
            sell_profit_probability DECIMAL(5, 4),
            sell_loss_probability DECIMAL(5, 4),
            
            -- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
            recommendation VARCHAR(20),  -- 'BUY', 'SELL', 'HOLD'
            confidence DECIMAL(5, 4),
            
            -- –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞)
            actual_outcome VARCHAR(20),
            actual_pnl DECIMAL(10, 4),
            
            created_at TIMESTAMP DEFAULT NOW()
        );
        """
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è predictions
        create_predictions_indexes = """
        CREATE INDEX IF NOT EXISTS idx_predictions_symbol_timestamp 
        ON model_predictions(symbol, timestamp);
        
        CREATE INDEX IF NOT EXISTS idx_predictions_datetime 
        ON model_predictions(datetime);
        """
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
        queries = [
            create_raw_data_table,
            create_indexes,
            create_processed_data_table,
            create_processed_indexes,
            create_model_metadata_table,
            create_sequences_table,
            create_predictions_table,
            create_predictions_indexes
        ]
        
        for i, query in enumerate(queries, 1):
            cursor.execute(query)
            logger.info(f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω –∑–∞–ø—Ä–æ—Å {i}/{len(queries)}")
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å JSONB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        cursor.execute("CREATE EXTENSION IF NOT EXISTS pg_trgm;")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É market_type –µ—Å–ª–∏ –µ—ë –µ—â–µ –Ω–µ—Ç
        logger.info("üîß –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ market_type...")
        cursor.execute("""
            ALTER TABLE raw_market_data 
            ADD COLUMN IF NOT EXISTS market_type VARCHAR(20) DEFAULT 'spot';
        """)
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è market_type
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_raw_market_data_market_type 
            ON raw_market_data(market_type);
        """)
        
        logger.info("‚úÖ –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
        cursor.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            ORDER BY table_name;
        """)
        
        tables = cursor.fetchall()
        logger.info("\nüìã –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã:")
        for table in tables:
            logger.info(f"   - {table[0]}")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}")
        raise


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML —Å–∏—Å—Ç–µ–º—ã –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_config()
    db_config = config['database']
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ë–î –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        create_database(db_config)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        init_tables(db_config)
        
        logger.info("\n‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!")
        logger.info("üìä –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å —Å–∫—Ä–∏–ø—Ç—ã:")
        logger.info("   1. python download_data.py - –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
        logger.info("   2. python prepare_dataset.py - –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        logger.info("   3. python train_model_postgres.py - –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise


if __name__ == "__main__":
    main()