#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å Bybit –≤ PostgreSQL
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –ë–î –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
"""

import requests
import pandas as pd
import time
import os
from datetime import datetime, timedelta
import json
from tqdm import tqdm
import psycopg2
from psycopg2.extras import execute_values
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError, wait, FIRST_COMPLETED
import threading
import signal
import sys
from contextlib import contextmanager
from psycopg2 import pool

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ñ–ª–∞–≥ –¥–ª—è graceful shutdown
shutdown_flag = threading.Event()

def signal_handler(signum, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è graceful shutdown"""
    logger.info("\n‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è. –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...")
    shutdown_flag.set()

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)


class PostgreSQLManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PostgreSQL —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏
    """

    def __init__(self, db_config: dict, max_connections: int = 30):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL

        Args:
            db_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
            max_connections: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ –ø—É–ª–µ
        """
        self.db_config = db_config.copy()
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç–æ–π –ø–∞—Ä–æ–ª—å
        if not self.db_config.get('password'):
            self.db_config.pop('password', None)
        self.connection = None
        self.connection_pool = None
        self.max_connections = max_connections

    def connect(self):
        """–°–æ–∑–¥–∞–µ—Ç –ø—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –ë–î –¥–ª—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            self.connection_pool = psycopg2.pool.ThreadedConnectionPool(
                1,  # –º–∏–Ω–∏–º—É–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                self.max_connections,  # –º–∞–∫—Å–∏–º—É–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                **self.db_config
            )
            
            # –û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–ø–æ—Ç–æ—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
            self.connection = psycopg2.connect(**self.db_config)
            self.connection.autocommit = True
            
            logger.info(f"‚úÖ –ü—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ PostgreSQL —Å–æ–∑–¥–∞–Ω (max: {self.max_connections})")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—É–ª–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π: {e}")
            raise
    
    @contextmanager
    def get_connection(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –ø—É–ª–∞"""
        conn = None
        try:
            conn = self.connection_pool.getconn()
            conn.autocommit = True
            yield conn
        finally:
            if conn:
                self.connection_pool.putconn(conn)

    def disconnect(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"""
        if self.connection:
            self.connection.close()
        if self.connection_pool:
            self.connection_pool.closeall()
        logger.info("üì§ –í—Å–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL –∑–∞–∫—Ä—ã—Ç—ã")

    def execute_query(self, query: str, params=None, fetch=False):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç SQL –∑–∞–ø—Ä–æ—Å

        Args:
            query: SQL –∑–∞–ø—Ä–æ—Å
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            fetch: –ù—É–∂–Ω–æ –ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ None
        """
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(query, params)
                if fetch:
                    return cursor.fetchall()
                return cursor.rowcount
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {e}")
            logger.error(f"–ó–∞–ø—Ä–æ—Å: {query}")
            raise

    def create_tables(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ç–∞–±–ª–∏—Ü—ã"""

        logger.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –≤ PostgreSQL...")

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—ã—Ä—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        create_raw_data_table = """
        CREATE TABLE IF NOT EXISTS raw_market_data (
            id BIGSERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            timestamp BIGINT NOT NULL,
            datetime TIMESTAMP NOT NULL,
            open DECIMAL(20, 8) NOT NULL,
            high DECIMAL(20, 8) NOT NULL,
            low DECIMAL(20, 8) NOT NULL,
            close DECIMAL(20, 8) NOT NULL,
            volume DECIMAL(20, 8) NOT NULL,
            turnover DECIMAL(20, 8) DEFAULT 0,
            interval_minutes INTEGER NOT NULL DEFAULT 15,
            market_type VARCHAR(20) DEFAULT 'spot',  -- –¢–∏–ø —Ä—ã–Ω–∫–∞: spot –∏–ª–∏ futures
            created_at TIMESTAMP DEFAULT NOW(),
            UNIQUE(symbol, timestamp, interval_minutes)
        );
        """

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        create_indexes = """
        CREATE INDEX IF NOT EXISTS idx_raw_market_data_symbol_timestamp 
        ON raw_market_data(symbol, timestamp);

        CREATE INDEX IF NOT EXISTS idx_raw_market_data_datetime 
        ON raw_market_data(datetime);

        CREATE INDEX IF NOT EXISTS idx_raw_market_data_symbol_datetime 
        ON raw_market_data(symbol, datetime);
        """

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
        create_processed_data_table = """
        CREATE TABLE IF NOT EXISTS processed_market_data (
            id BIGSERIAL PRIMARY KEY,
            raw_data_id BIGINT REFERENCES raw_market_data(id),
            symbol VARCHAR(20) NOT NULL,
            timestamp BIGINT NOT NULL,
            datetime TIMESTAMP NOT NULL,

            -- –ë–∞–∑–æ–≤—ã–µ OHLCV
            open DECIMAL(20, 8) NOT NULL,
            high DECIMAL(20, 8) NOT NULL,
            low DECIMAL(20, 8) NOT NULL,
            close DECIMAL(20, 8) NOT NULL,
            volume DECIMAL(20, 8) NOT NULL,

            -- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (JSON –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏)
            technical_indicators JSONB,

            -- –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–º–µ—Ç–∫–∏)
            buy_profit_target INTEGER DEFAULT 0,
            buy_loss_target INTEGER DEFAULT 0,
            sell_profit_target INTEGER DEFAULT 0,
            sell_loss_target INTEGER DEFAULT 0,

            -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            processing_version VARCHAR(10) DEFAULT '1.0',
            created_at TIMESTAMP DEFAULT NOW(),
            updated_at TIMESTAMP DEFAULT NOW(),

            UNIQUE(symbol, timestamp)
        );
        """

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è processed_data
        create_processed_indexes = """
        CREATE INDEX IF NOT EXISTS idx_processed_market_data_symbol_timestamp 
        ON processed_market_data(symbol, timestamp);

        CREATE INDEX IF NOT EXISTS idx_processed_market_data_targets 
        ON processed_market_data(buy_profit_target, buy_loss_target, sell_profit_target, sell_loss_target);

        CREATE INDEX IF NOT EXISTS idx_processed_technical_indicators 
        ON processed_market_data USING GIN (technical_indicators);
        """

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
        create_model_metadata_table = """
        CREATE TABLE IF NOT EXISTS model_metadata (
            id SERIAL PRIMARY KEY,
            model_name VARCHAR(100) NOT NULL,
            model_type VARCHAR(50) NOT NULL,
            version VARCHAR(20) NOT NULL,
            feature_columns JSONB,
            training_config JSONB,
            performance_metrics JSONB,
            file_path VARCHAR(500),
            created_at TIMESTAMP DEFAULT NOW(),
            is_active BOOLEAN DEFAULT TRUE
        );
        """

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        create_sequences_table = """
        CREATE TABLE IF NOT EXISTS training_sequences (
            id BIGSERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            sequence_start_timestamp BIGINT NOT NULL,
            sequence_end_timestamp BIGINT NOT NULL,
            sequence_length INTEGER NOT NULL,
            features JSONB NOT NULL,
            buy_profit_target INTEGER DEFAULT 0,
            buy_loss_target INTEGER DEFAULT 0,
            sell_profit_target INTEGER DEFAULT 0,
            sell_loss_target INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT NOW()
        );
        """

        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
        queries = [
            create_raw_data_table,
            create_indexes,
            create_processed_data_table,
            create_processed_indexes,
            create_model_metadata_table,
            create_sequences_table
        ]

        for query in queries:
            self.execute_query(query)

        logger.info("‚úÖ –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")


class BybitDataDownloader:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å Bybit –≤ PostgreSQL
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –∫–∞–∫ —Å–ø–æ—Ç–æ–≤—ã—Ö, —Ç–∞–∫ –∏ —Ñ—å—é—á–µ—Ä—Å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """

    def __init__(self, db_manager: PostgreSQLManager, market_type='futures'):
        self.base_url = "https://api.bybit.com"
        self.session = requests.Session()
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–∞–π–º–∞—É—Ç–æ–≤ –¥–ª—è requests
        self.session.timeout = 30  # 30 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
        self.db = db_manager
        self.market_type = market_type  # 'spot' –∏–ª–∏ 'futures'
        # Thread-local storage –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–≤
        self.thread_local = threading.local()

    def get_klines(self, symbol: str, interval: str, start_time: int, end_time: int, limit: int = 1000):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ —Å Bybit

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT)
            interval: –¢–∞–π–º—Ñ—Ä–µ–π–º (1, 3, 5, 15, 30, 60, 120, 240, 360, 720, D, W, M)
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            end_time: –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π –∑–∞ –∑–∞–ø—Ä–æ—Å (–º–∞–∫—Å 1000)

        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–≤–µ—á–µ–π
        """

        url = f"{self.base_url}/v5/market/kline"
        params = {
            'category': 'linear' if self.market_type == 'futures' else 'spot',  # linear –¥–ª—è USDT perpetual —Ñ—å—é—á–µ—Ä—Å–æ–≤
            'symbol': symbol,
            'interval': interval,
            'start': start_time,
            'end': end_time,
            'limit': limit
        }

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            if shutdown_flag.is_set():
                return []
                
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()

            if data.get('retCode') == 0:
                return data.get('result', {}).get('list', [])
            else:
                logger.error(f"–û—à–∏–±–∫–∞ API: {data.get('retMsg', 'Unknown error')}")
                return []

        except requests.exceptions.Timeout:
            logger.error(f"–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {symbol}")
            return []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return []

    def insert_raw_data_batch(self, symbol: str, klines_data: list, interval_minutes: int = 15):
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π –≤ –ë–î –±–∞—Ç—á–æ–º

        Args:
            symbol: –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            klines_data: –°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π
            interval_minutes: –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–Ω—É—Ç–∞—Ö
        """

        if not klines_data:
            return 0

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        values_to_insert = []
        for kline in klines_data:
            timestamp = int(kline[0])
            dt = datetime.fromtimestamp(timestamp / 1000)

            values_to_insert.append((
                symbol,
                timestamp,
                dt,
                float(kline[1]),  # open
                float(kline[2]),  # high
                float(kline[3]),  # low
                float(kline[4]),  # close
                float(kline[5]),  # volume
                float(kline[6]) if len(kline) > 6 else 0.0,  # turnover
                interval_minutes,
                self.market_type  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏–ø —Ä—ã–Ω–∫–∞
            ))

        # SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ —Å ON CONFLICT
        insert_query = """
        INSERT INTO raw_market_data 
        (symbol, timestamp, datetime, open, high, low, close, volume, turnover, interval_minutes, market_type)
        VALUES %s
        ON CONFLICT (symbol, timestamp, interval_minutes) 
        DO UPDATE SET
            open = EXCLUDED.open,
            high = EXCLUDED.high,
            low = EXCLUDED.low,
            close = EXCLUDED.close,
            volume = EXCLUDED.volume,
            turnover = EXCLUDED.turnover,
            market_type = EXCLUDED.market_type
        """

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–∑ –ø—É–ª–∞ –¥–ª—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            with self.db.get_connection() as conn:
                with conn.cursor() as cursor:
                    execute_values(cursor, insert_query, values_to_insert)
            return len(values_to_insert)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            return 0

    def download_historical_data(self, symbol: str, interval: str = '15', days: int = 365 * 3, check_existing=True):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –≤ PostgreSQL

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            interval: –¢–∞–π–º—Ñ—Ä–µ–π–º (15 –¥–ª—è 15-–º–∏–Ω—É—Ç–Ω—ã—Ö —Å–≤–µ—á–µ–π)
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3 –≥–æ–¥–∞)
            check_existing: –ü—Ä–æ–≤–µ—Ä—è—Ç—å –ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏
        """

        logger.info(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö {symbol} ({interval} –∏–Ω—Ç–µ—Ä–≤–∞–ª) –∑–∞ {days} –¥–Ω–µ–π")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        existing_data = self.db.execute_query(
            """SELECT COUNT(*), MIN(datetime), MAX(datetime) 
               FROM raw_market_data 
               WHERE symbol = %s AND interval_minutes = %s AND market_type = %s""",
            (symbol, int(interval), self.market_type),
            fetch=True
        )[0]
        
        existing_count = existing_data[0]
        existing_start = existing_data[1]
        existing_end = existing_data[2]

        if existing_count > 0:
            logger.info(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {existing_count} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è {symbol}")
            if existing_start and existing_end:
                logger.info(f"   üìÖ –ü–µ—Ä–∏–æ–¥: {existing_start} - {existing_end}")
                
                # –ï—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞ –∏ –¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if check_existing:
                    days_since_update = (datetime.now() - existing_end).days
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ —Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π
                    if days_since_update < 7:
                        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ {symbol} –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–µ–∂–∏–µ (–æ–±–Ω–æ–≤–ª–µ–Ω—ã {days_since_update} –¥–Ω–µ–π –Ω–∞–∑–∞–¥), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        
                        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
                        stats_query = """
                        SELECT MIN(close), MAX(close), AVG(volume)
                        FROM raw_market_data 
                        WHERE symbol = %s AND interval_minutes = %s
                        """
                        stats_data = self.db.execute_query(stats_query, (symbol, int(interval)), fetch=True)[0]
                        
                        return {
                            'symbol': symbol,
                            'interval': interval,
                            'total_records': existing_count,
                            'newly_inserted': 0,
                            'start_date': existing_start,
                            'end_date': existing_end,
                            'min_price': float(stats_data[0]) if stats_data[0] else 0,
                            'max_price': float(stats_data[1]) if stats_data[1] else 0,
                            'avg_volume': float(stats_data[2]) if stats_data[2] else 0,
                            'skipped': True
                        }
                    else:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
                        logger.info(f"üì• –î–æ–∫–∞—á–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days_since_update} –¥–Ω–µ–π –¥–ª—è {symbol}")
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
                        approx_new_records = days_since_update * 24 * 4  # 4 –∑–∞–ø–∏—Å–∏ –≤ —á–∞—Å –¥–ª—è 15-–º–∏–Ω –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
                        logger.info(f"   üìà –û–∂–∏–¥–∞–µ—Ç—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ {approx_new_records} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")

        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏
        end_time = int(datetime.now().timestamp() * 1000)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ, –Ω–∞—á–∏–Ω–∞–µ–º —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã
        if existing_end and existing_count > 0:
            # –î–æ–±–∞–≤–ª—è–µ–º 1 –º–∏–Ω—É—Ç—É –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç–µ —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å
            start_time = int((existing_end + timedelta(minutes=1)).timestamp() * 1000)
            logger.info(f"üìç –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Å {existing_end + timedelta(minutes=1)}")
        else:
            start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        interval_ms = self._get_interval_ms(interval)
        max_klines_per_request = 1000
        chunk_size_ms = interval_ms * max_klines_per_request

        # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ (—ç—Ç–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
        # –†–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –∏–∑-–∑–∞ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π API Bybit
        estimated_requests = max(1, (end_time - start_time) // chunk_size_ms + 1)
        total_requests = estimated_requests

        total_inserted = 0
        current_start = start_time

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Å—á–µ—Ç—á–∏–∫ –≤–º–µ—Å—Ç–æ tqdm –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤
        request_count = 0
        last_log_time = time.time()
        
        while current_start < end_time and not shutdown_flag.is_set():
            current_end = min(current_start + chunk_size_ms, end_time)

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            klines = self.get_klines(symbol, interval, current_start, current_end)

            if klines:
                # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ –ë–î
                inserted = self.insert_raw_data_batch(symbol, klines, int(interval))
                total_inserted += inserted

                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é
                last_timestamp = int(klines[-1][0])
                current_start = last_timestamp + interval_ms
            else:
                current_start = current_end

            request_count += 1
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥ –∏–ª–∏ –∫–∞–∂–¥—ã–µ 10 –∑–∞–ø—Ä–æ—Å–æ–≤
            current_time = time.time()
            if request_count % 10 == 0 or (current_time - last_log_time) > 5:
                # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–∏
                time_progress = ((current_start - start_time) / (end_time - start_time)) * 100
                time_progress = min(time_progress, 100.0)
                
                # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –±–æ–ª—å—à–µ —á–µ–º –æ–∂–∏–¥–∞–ª–æ—Å—å, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                if request_count > total_requests:
                    logger.info(f"üìä {symbol}: {time_progress:.1f}% –ø–æ –≤—Ä–µ–º–µ–Ω–∏ ({request_count} –∑–∞–ø—Ä–æ—Å–æ–≤, –æ–∂–∏–¥–∞–ª–æ—Å—å ~{total_requests})")
                else:
                    logger.info(f"üìä {symbol}: {time_progress:.1f}% ({request_count}/{total_requests})")
                    
                last_log_time = current_time
                
            time.sleep(0.1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        final_count = self.db.execute_query(
            "SELECT COUNT(*) FROM raw_market_data WHERE symbol = %s AND interval_minutes = %s",
            (symbol, int(interval)),
            fetch=True
        )[0][0]

        # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö
        period_query = """
        SELECT MIN(datetime), MAX(datetime), MIN(close), MAX(close), AVG(volume)
        FROM raw_market_data 
        WHERE symbol = %s AND interval_minutes = %s
        """
        period_data = self.db.execute_query(period_query, (symbol, int(interval)), fetch=True)[0]

        stats = {
            'symbol': symbol,
            'interval': interval,
            'total_records': final_count,
            'newly_inserted': total_inserted,
            'start_date': period_data[0],
            'end_date': period_data[1],
            'min_price': float(period_data[2]) if period_data[2] else 0,
            'max_price': float(period_data[3]) if period_data[3] else 0,
            'avg_volume': float(period_data[4]) if period_data[4] else 0,
            'skipped': False
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
        if shutdown_flag.is_set():
            logger.warning(f"‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ {symbol} –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        else:
            if total_inserted > 0:
                logger.info(f"‚úÖ {symbol}: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {total_inserted} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –∑–∞ {request_count} –∑–∞–ø—Ä–æ—Å–æ–≤ (–≤—Å–µ–≥–æ: {final_count})")
            else:
                logger.info(f"‚úÖ {symbol}: –¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã (–≤—Å–µ–≥–æ: {final_count} –∑–∞–ø–∏—Å–µ–π)")

        return stats

    def _get_interval_ms(self, interval: str) -> int:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã"""

        interval_map = {
            '1': 60 * 1000,
            '3': 3 * 60 * 1000,
            '5': 5 * 60 * 1000,
            '15': 15 * 60 * 1000,
            '30': 30 * 60 * 1000,
            '60': 60 * 60 * 1000,
            '120': 120 * 60 * 1000,
            '240': 240 * 60 * 1000,
            'D': 24 * 60 * 60 * 1000,
        }

        return interval_map.get(interval, 15 * 60 * 1000)

    def download_multiple_symbols(self, symbols: list, interval: str = '15', days: int = 365 * 3, max_workers: int = 5):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å

        Args:
            symbols: –°–ø–∏—Å–æ–∫ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä
            interval: –¢–∞–π–º—Ñ—Ä–µ–π–º
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
            max_workers: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤

        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        """

        results = {}
        lock = threading.Lock()
        
        def download_symbol(symbol):
            """–§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞"""
            thread_name = threading.current_thread().name
            try:
                logger.info(f"üîÑ [{thread_name}] –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {symbol}")
                
                stats = self.download_historical_data(
                    symbol=symbol,
                    interval=interval,
                    days=days
                )
                
                with lock:
                    results[symbol] = {'success': True, 'stats': stats}
                    
                return symbol, True
            except Exception as e:
                logger.error(f"‚ùå [{thread_name}] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {symbol}: {e}")
                with lock:
                    results[symbol] = {'success': False, 'error': str(e)}
                return symbol, False

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä –¥–ª—è –æ–±—â–µ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        completed_count = 0
        with tqdm(total=len(symbols), desc="–û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏", position=0) as pbar:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏
                futures = {executor.submit(download_symbol, symbol): symbol for symbol in symbols}
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                remaining_futures = list(futures.keys())
                
                while remaining_futures and not shutdown_flag.is_set():
                    # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                    done, remaining_futures = wait(
                        remaining_futures, 
                        timeout=60,  # 60 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
                        return_when=FIRST_COMPLETED
                    )
                    
                    for future in done:
                        symbol = futures[future]
                        try:
                            symbol_result, success = future.result(timeout=5)
                            completed_count += 1
                            pbar.update(1)
                            if success:
                                logger.info(f"‚úÖ {symbol_result} –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ ({completed_count}/{len(symbols)})")
                            else:
                                logger.warning(f"‚ö†Ô∏è {symbol_result} –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å")
                        except TimeoutError:
                            logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –¥–ª—è {symbol}")
                            with lock:
                                results[symbol] = {'success': False, 'error': 'Timeout'}
                            pbar.update(1)
                        except Exception as e:
                            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è {symbol}: {e}")
                            with lock:
                                results[symbol] = {'success': False, 'error': str(e)}
                            pbar.update(1)
                
                # –û—Ç–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–¥–∞—á–∏ –ø—Ä–∏ shutdown
                if shutdown_flag.is_set():
                    logger.info("üõë –û—Ç–º–µ–Ω–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∑–∞–¥–∞—á...")
                    for future in remaining_futures:
                        future.cancel()
                    executor.shutdown(wait=False)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        successful = sum(1 for r in results.values() if r.get('success', False))
        skipped = sum(1 for r in results.values() if r.get('success') and r.get('stats', {}).get('skipped', False))
        failed = len(results) - successful
        
        logger.info(f"\n{'=' * 60}")
        logger.info(f"üìä –ò–¢–û–ì–ò –ú–ù–û–ì–û–ü–û–¢–û–ß–ù–û–ô –ó–ê–ì–†–£–ó–ö–ò:")
        logger.info(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"   ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ): {skipped} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"   ‚ùå –û—à–∏–±–∫–∏: {failed} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"   üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–æ—Ç–æ–∫–æ–≤: {max_workers}")
        logger.info(f"{'=' * 60}")

        return results

    def get_database_stats(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞–Ω–Ω—ã–º –≤ –ë–î"""

        stats_query = """
        SELECT 
            symbol,
            COUNT(*) as total_records,
            MIN(datetime) as start_date,
            MAX(datetime) as end_date,
            MIN(close) as min_price,
            MAX(close) as max_price,
            AVG(volume) as avg_volume
        FROM raw_market_data 
        WHERE interval_minutes = 15
        GROUP BY symbol
        ORDER BY symbol
        """

        results = self.db.execute_query(stats_query, fetch=True)

        total_records = 0
        stats = {}

        for row in results:
            symbol_stats = {
                'total_records': row[1],
                'start_date': row[2],
                'end_date': row[3],
                'min_price': float(row[4]),
                'max_price': float(row[5]),
                'avg_volume': float(row[6])
            }
            stats[row[0]] = symbol_stats
            total_records += row[1]

        logger.info(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
        logger.info(f"   üóÉÔ∏è –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(stats)}")
        logger.info(f"   üìà –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}")

        return stats, total_records


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    import yaml
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    db_config = config['database']

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ë–î
    db_manager = PostgreSQLManager(db_config)

    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        db_manager.connect()

        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        db_manager.create_tables()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è —Ñ—å—é—á–µ—Ä—Å–æ–≤
        market_type = config['data_download'].get('market_type', 'futures')
        downloader = BybitDataDownloader(db_manager, market_type=market_type)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        top_symbols = config['data_download']['symbols']
        # –ò—Å–∫–ª—é—á–∞–µ–º TESTUSDT
        top_symbols = [s for s in top_symbols if 'TEST' not in s]
        interval = config['data_download']['interval']
        days = config['data_download']['days']

        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(top_symbols)} —Å–∏–º–≤–æ–ª–æ–≤ –≤ PostgreSQL")
        logger.info(f"üìä –¢–∞–π–º—Ñ—Ä–µ–π–º: {interval} –º–∏–Ω—É—Ç")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {days} –¥–Ω–µ–π")
        logger.info(f"üóÉÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_config['dbname']}")
        logger.info(f"üìà –¢–∏–ø —Ä—ã–Ω–∫–∞: {market_type.upper()}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 25)
        max_workers = config['data_download'].get('max_workers', 25)
        logger.info(f"üîß –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤: {max_workers}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –º–æ–Ω–µ—Ç—ã –∑–∞ 3 –≥–æ–¥–∞ —Å –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å—é
        results = downloader.download_multiple_symbols(top_symbols, interval, days, max_workers=max_workers)

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(f"\n{'=' * 50}")
        logger.info(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        logger.info(f"{'=' * 50}")

        successful = sum(1 for r in results.values() if r.get('success', False))
        skipped = sum(1 for r in results.values() if r.get('success') and r.get('stats', {}).get('skipped', False))
        newly_downloaded = successful - skipped
        failed = len(results) - successful

        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful}")
        logger.info(f"   üì• –ù–æ–≤—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫: {newly_downloaded}")
        logger.info(f"   ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ): {skipped}")
        logger.info(f"‚ùå –û—à–∏–±–æ–∫: {failed}")
        
        # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
        total_new_records = sum(
            r.get('stats', {}).get('newly_inserted', 0) 
            for r in results.values() 
            if r.get('success', False)
        )
        logger.info(f"üìà –í—Å–µ–≥–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–æ–±–∞–≤–ª–µ–Ω–æ: {total_new_records:,}")

        if failed > 0:
            logger.info(f"\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å:")
            for symbol, result in results.items():
                if not result.get('success', False):
                    logger.info(f"   {symbol}: {result.get('error', 'Unknown error')}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ë–î
        stats, total_records = downloader.get_database_stats()
        logger.info(f"\nüìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–î:")
        logger.info(f"   üíæ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î: {total_records:,}")
        logger.info(f"   üìà –°–∏–º–≤–æ–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏: {len(stats)}")

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        db_manager.disconnect()


if __name__ == "__main__":
    main()