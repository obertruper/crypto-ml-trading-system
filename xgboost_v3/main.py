#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è XGBoost v3.0
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import argparse
import logging
import time
import subprocess
from pathlib import Path
from typing import Dict, List
import pandas as pd
import numpy as np

from config import Config
from data import DataLoader, DataPreprocessor, FeatureEngineer
from data.cacher import CacheManager
from models import XGBoostTrainer, EnsembleModel, OptunaOptimizer, DataBalancer
from utils import LoggingManager, ReportGenerator
from utils.feature_selector import FeatureSelector
from utils.feature_importance_validator import FeatureImportanceValidator

logger = logging.getLogger(__name__)


def analyze_feature_importance(models: Dict, feature_names: List[str]) -> Dict:
    """–ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    def get_category(feature):
        feature_lower = feature.lower()
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        technical_patterns = [
            'rsi', 'macd', 'bb_', 'bollinger', 'adx', 'atr', 'stoch', 'williams', 
            'mfi', 'cci', 'cmf', 'obv', 'ema', 'sma', 'vwap', 'sar', 'ich_',
            'aroon', 'kc_', 'dc_', 'volume_ratio', 'price_momentum', 'volatility',
            'hl_spread', 'close_ratio', 'upper_shadow', 'lower_shadow', 'body_size',
            'open_ratio', 'high_ratio', 'low_ratio', 'log_return', 'log_volume',
            'price_to_', 'volume_position', 'cumulative_volume', 'higher_high',
            'lower_low', 'consecutive_', 'inside_bar', 'pin_bar', 'spread_approximation',
            'price_efficiency', 'gk_volatility', 'position_in_', 'trend_'
        ]
        for pattern in technical_patterns:
            if pattern in feature_lower:
                return '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã'
        
        # BTC –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
        btc_patterns = ['btc_', 'bitcoin', 'relative_strength_btc']
        for pattern in btc_patterns:
            if pattern in feature_lower:
                return 'BTC –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏'
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        time_patterns = ['hour', 'dow', 'day', 'week', 'month', 'time', 'weekend']
        for pattern in time_patterns:
            if pattern in feature_lower:
                return '–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏'
        
        # –†—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã
        if 'market_regime' in feature_lower:
            return '–†—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã'
            
        # –°–∏–º–≤–æ–ª—ã
        symbol_patterns = ['is_btc', 'is_eth', 'is_bnb', 'is_xrp', 'is_ada', 'is_doge', 
                          'is_sol', 'is_dot', 'is_matic', 'is_shib']
        for pattern in symbol_patterns:
            if pattern in feature_lower:
                return '–°–∏–º–≤–æ–ª—ã'
        
        return '–î—Ä—É–≥–∏–µ'
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å–æ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    all_importances = {}
    for direction in ['buy', 'sell']:
        ensemble = models[direction]['ensemble']
        for i, model in enumerate(ensemble.models):
            if hasattr(model, 'feature_importances_'):
                for feat, imp in zip(feature_names, model.feature_importances_):
                    if feat not in all_importances:
                        all_importances[feat] = []
                    all_importances[feat].append(imp)
    
    # –£—Å—Ä–µ–¥–Ω—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç–∏
    avg_importances = {feat: np.mean(imps) for feat, imps in all_importances.items()}
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_analysis = {}
    for feat, imp in avg_importances.items():
        cat = get_category(feat)
        if cat not in category_analysis:
            category_analysis[cat] = {
                'features': [],
                'importances': [],
                'count': 0,
                'total_importance': 0
            }
        category_analysis[cat]['features'].append(feat)
        category_analysis[cat]['importances'].append(imp)
        category_analysis[cat]['count'] += 1
        category_analysis[cat]['total_importance'] += imp
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {}
    total_features = sum(cat['count'] for cat in category_analysis.values())
    
    for cat, data in category_analysis.items():
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        sorted_features = sorted(zip(data['features'], data['importances']), 
                               key=lambda x: x[1], reverse=True)
        
        results[cat] = {
            'count': data['count'],
            'percentage': (data['count'] / total_features * 100) if total_features > 0 else 0,
            'total_importance': data['total_importance'],
            'top_features': [f[0] for f in sorted_features[:5]]
        }
    
    return results


def parse_args():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description="XGBoost v3.0 Training")
    
    parser.add_argument('--config', type=str, default=None,
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (YAML)')
    
    parser.add_argument('--task', type=str, default='classification_binary',
                       choices=['classification_binary', 'classification_multi', 'regression'],
                       help='–¢–∏–ø –∑–∞–¥–∞—á–∏')
    
    parser.add_argument('--test-mode', action='store_true',
                       help='–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—Ç–æ–ª—å–∫–æ 2 —Å–∏–º–≤–æ–ª–∞)')
    
    parser.add_argument('--no-cache', action='store_true',
                       help='–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à')
    
    parser.add_argument('--optimize', action='store_true',
                       help='–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤')
    
    parser.add_argument('--ensemble-size', type=int, default=None,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤ –∞–Ω—Å–∞–º–±–ª–µ')
    
    parser.add_argument('--gpu', action='store_true',
                       help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')
    
    return parser.parse_args()




def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    args = parse_args()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if args.config:
        config = Config.from_yaml(args.config)
    else:
        config = Config()
        
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    config.training.task_type = args.task
    config.training.test_mode = args.test_mode
    config.training.use_cache = not args.no_cache
    
    if args.ensemble_size:
        config.training.ensemble_size = args.ensemble_size
        
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU
    if args.gpu:
        logger.info("üöÄ GPU —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
        try:
            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
            if result.returncode == 0:
                logger.info("‚úÖ GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω")
                config.model.tree_method = "gpu_hist"
                config.model.predictor = "gpu_predictor"
                # –î–æ–±–∞–≤–ª—è–µ–º gpu_id –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                config.model.gpu_id = 0
            else:
                logger.warning("‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
                config.model.tree_method = "hist"
                config.model.predictor = "cpu_predictor"
        except:
            logger.warning("‚ö†Ô∏è nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
            config.model.tree_method = "hist"
            config.model.predictor = "cpu_predictor"
    else:
        logger.info("üíª CPU —Ä–µ–∂–∏–º")
        config.model.tree_method = "hist"
        config.model.predictor = "cpu_predictor"
        
    # –í–ê–ñ–ù–û: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
    if not config.training.test_mode:
        logger.warning("‚ö†Ô∏è –ü–†–û–î–ê–ö–®–ù –†–ï–ñ–ò–ú: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!")
        config.training.feature_selection_method = "hierarchical"
        
    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config.validate()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    log_dir = config.get_log_dir()
    logging_manager = LoggingManager(log_dir)
    logging_manager.setup_logging()
    
    logger.info("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë        XGBoost v3.0 - ML Trading         ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    logger.info(config)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config.save(log_dir / "config.yaml")
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        logger.info("\n" + "="*60)
        logger.info("üì• –®–ê–ì 1: –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        cacher = CacheManager(config)
        data_loader = DataLoader(config)
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫—ç—à–∞
        df = None
        if config.training.use_cache:
            df = cacher.load_from_cache()
            
        if df is None:
            data_loader.connect()
            df = data_loader.load_data()
            data_loader.validate_data(df)
            data_loader.disconnect()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            if config.training.use_cache:
                cacher.save_to_cache(df)
                
        # 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        logger.info("\n" + "="*60)
        logger.info("üîß –®–ê–ì 2: –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        preprocessor = DataPreprocessor(config)
        
        # 3. –ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ X –∏ y)
        logger.info("\n" + "="*60)
        logger.info("üî¨ –®–ê–ì 3: –ò–ù–ñ–ï–ù–ï–†–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í")
        logger.info("="*60)
        
        feature_engineer = FeatureEngineer(config)
        df = feature_engineer.create_features(df)
        
        # –¢–µ–ø–µ—Ä—å –∏–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        X, y_buy, y_sell = preprocessor.preprocess(df)
        
        # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ expected returns
        logger.info("\nüìä –ü–†–û–í–ï–†–ö–ê EXPECTED RETURNS:")
        logger.info(f"   Buy Expected Return - min: {y_buy.min():.2f}%, max: {y_buy.max():.2f}%, mean: {y_buy.mean():.2f}%")
        logger.info(f"   Sell Expected Return - min: {y_sell.min():.2f}%, max: {y_sell.max():.2f}%, mean: {y_sell.mean():.2f}%")
        logger.info(f"   Buy > 0%: {(y_buy > 0).mean()*100:.1f}%, Buy > 0.5%: {(y_buy > 0.5).mean()*100:.1f}%")
        logger.info(f"   Sell > 0%: {(y_sell > 0).mean()*100:.1f}%, Sell > 0.5%: {(y_sell > 0.5).mean()*100:.1f}%")
        
        if y_buy.isna().any() or y_sell.isna().any():
            logger.error("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –≤ expected returns!")
            logger.error(f"   Buy NaN: {y_buy.isna().sum()}, Sell NaN: {y_sell.isna().sum()}")
            raise ValueError("Expected returns —Å–æ–¥–µ—Ä–∂–∞—Ç NaN –∑–Ω–∞—á–µ–Ω–∏—è!")
        
        # 4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        logger.info("\n" + "="*60)
        logger.info("üìä –®–ê–ì 4: –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        data_splits = preprocessor.split_data(X, y_buy, y_sell)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –º–µ—Ç–∫–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if config.training.task_type != "regression":
            for direction in ['buy', 'sell']:
                y_train_binary, y_test_binary = preprocessor.transform_to_classification_labels(
                    data_splits[direction]['y_train'],
                    data_splits[direction]['y_test']
                )
                data_splits[direction]['y_train'] = y_train_binary
                data_splits[direction]['y_test'] = y_test_binary
                
        # 5. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info("\n" + "="*60)
        logger.info("üìè –®–ê–ì 5: –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í")
        logger.info("="*60)
        
        for direction in ['buy', 'sell']:
            X_train_norm, X_test_norm = preprocessor.normalize_features(
                data_splits[direction]['X_train'],
                data_splits[direction]['X_test']
            )
            data_splits[direction]['X_train'] = X_train_norm
            data_splits[direction]['X_test'] = X_test_norm
        
        # 5.5. –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info("\n" + "="*60)
        logger.info("üéØ –®–ê–ì 5.5: –û–¢–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í")
        logger.info("="*60)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º feature selection –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        # –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è 60/20/10/10
        if config.training.test_mode:
            # –¢–µ—Å—Ç —Ä–µ–∂–∏–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            logger.info("üéØ –¢–µ—Å—Ç —Ä–µ–∂–∏–º: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (80 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)")
            feature_selector = FeatureSelector(method="hierarchical", top_k=80)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            X_all_train = pd.concat([data_splits['buy']['X_train'], data_splits['sell']['X_train']])
            y_all_train = pd.concat([data_splits['buy']['y_train'], data_splits['sell']['y_train']])
            
            # –û—Ç–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            _, selected_features = feature_selector.select_features(X_all_train, y_all_train)
        else:
            # –ü—Ä–æ–¥–∞–∫—à–µ–Ω —Ä–µ–∂–∏–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            logger.info("üéØ –ü–†–û–î–ê–ö–®–ï–ù —Ä–µ–∂–∏–º: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (120 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)")
            logger.info("   –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
            feature_selector = FeatureSelector(method="hierarchical", top_k=120)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            X_all_train = pd.concat([data_splits['buy']['X_train'], data_splits['sell']['X_train']])
            y_all_train = pd.concat([data_splits['buy']['y_train'], data_splits['sell']['y_train']])
            
            # –û—Ç–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            _, selected_features = feature_selector.select_features(X_all_train, y_all_train)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—Ç–±–æ—Ä –∫–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º
        for direction in ['buy', 'sell']:
            data_splits[direction]['X_train'] = data_splits[direction]['X_train'][selected_features]
            data_splits[direction]['X_test'] = data_splits[direction]['X_test'][selected_features]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        preprocessor.feature_names = selected_features
        
        # –ù–û–í–û–ï: –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info(f"\nüìã –î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –û–¢–û–ë–†–ê–ù–ù–´–• {len(selected_features)} –ü–†–ò–ó–ù–ê–ö–û–í:")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        try:
            from config.feature_mapping import get_feature_category
            category_features = {}
            for feature in selected_features:
                cat = get_feature_category(feature)
                if cat not in category_features:
                    category_features[cat] = []
                category_features[cat].append(feature)
            
            for category, features in category_features.items():
                logger.info(f"   {category} ({len(features)}): {', '.join(features[:5])}"
                          + (f" ...–∏ –µ—â–µ {len(features)-5}" if len(features) > 5 else ""))
        except ImportError:
            logger.info(f"   –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
            logger.info(f"   –ü–µ—Ä–≤—ã–µ 10: {', '.join(selected_features[:10])}")
        
        # –ù–û–í–û–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        logger.info("\n" + "="*60)
        logger.info("üîç –í–ê–õ–ò–î–ê–¶–ò–Ø –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í")
        logger.info("="*60)
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏
        try:
            from config.feature_mapping import get_feature_category, get_category_targets
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            category_counts = {}
            for feature in selected_features:
                cat = get_feature_category(feature)
                category_counts[cat] = category_counts.get(cat, 0) + 1
            
            # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
            targets = get_category_targets()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            all_ok = True
            for category, target_percent in targets.items():
                count = category_counts.get(category, 0)
                actual_percent = count / len(selected_features) * 100 if selected_features else 0
                deviation = abs(actual_percent - target_percent)
                
                if deviation > 10:  # –î–æ–ø—É—Å—Ç–∏–º–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ 10%
                    status = "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –û–¢–ö–õ–û–ù–ï–ù–ò–ï!"
                    all_ok = False
                elif deviation > 5:
                    status = "‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ"
                else:
                    status = "‚úÖ"
                    
                logger.info(f"   {category}: {count} ({actual_percent:.1f}%) {status} [—Ü–µ–ª—å: {target_percent}%]")
            
            if not all_ok:
                logger.warning("\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è –æ—Ç —Ü–µ–ª–µ–≤–æ–≥–æ!")
                logger.warning("   –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö!")
                
        except ImportError:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (feature_mapping.py –Ω–µ –Ω–∞–π–¥–µ–Ω)")
            
        # 6. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        logger.info("\n" + "="*60)
        logger.info("‚öñÔ∏è –®–ê–ì 6: –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        balancer = DataBalancer(config)
        
        for direction in ['buy', 'sell']:
            logger.info(f"\nüéØ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–ª—è {direction.upper()}")
            
            X_balanced, y_balanced = balancer.balance_data(
                data_splits[direction]['X_train'],
                data_splits[direction]['y_train'],
                is_classification=(config.training.task_type != "regression")
            )
            
            data_splits[direction]['X_train'] = X_balanced
            data_splits[direction]['y_train'] = y_balanced
            
        # 7. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        logger.info("\n" + "="*60)
        logger.info("üöÄ –®–ê–ì 7: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        logger.info("="*60)
        
        models = {}
        
        for direction in ['buy', 'sell']:
            logger.info(f"\n{'='*60}")
            logger.info(f"üéØ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò: {direction.upper()}")
            logger.info(f"{'='*60}")
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            # –í —Ç–µ—Å—Ç —Ä–µ–∂–∏–º–µ –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if args.optimize or config.training.test_mode:
                logger.info("\nüîç –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
                optimizer = OptunaOptimizer(config)
                
                # –î–ª—è —Ç–µ—Å—Ç —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –ª—É—á—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                # –í –ø—Ä–æ–¥–∞–∫—à–Ω —Ä–µ–∂–∏–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—â–µ –±–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫
                if config.training.test_mode:
                    n_trials = 50  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 20 –¥–æ 50
                else:
                    # –ü—Ä–æ–¥–∞–∫—à–µ–Ω - –µ—â–µ –±–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫
                    n_trials = 200 if config.training.ensemble_size > 5 else config.training.optuna_trials
                
                best_params = optimizer.optimize(
                    data_splits[direction]['X_train'],
                    data_splits[direction]['y_train'],
                    n_trials=n_trials,
                    model_type=direction
                )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
                for key, value in best_params.items():
                    if hasattr(config.model, key):
                        setattr(config.model, key, value)
                        
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                if config.training.save_plots:
                    plot_path = log_dir / f"{direction}_optuna_history.png"
                    optimizer.plot_optimization_history(str(plot_path))
                        
            # –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
            ensemble = EnsembleModel(config)
            ensemble_models = ensemble.train_ensemble(
                data_splits[direction]['X_train'],
                data_splits[direction]['y_train'],
                data_splits[direction]['X_test'],
                data_splits[direction]['y_test']
            )
            
            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            test_metrics = ensemble.evaluate(
                data_splits[direction]['X_test'],
                data_splits[direction]['y_test'],
                f"Test ({direction})"
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            if config.training.save_models:
                model_dir = log_dir / f"{direction}_models"
                model_dir.mkdir(exist_ok=True)
                ensemble.save_ensemble(str(model_dir))
                
            models[direction] = {
                'ensemble': ensemble,
                'test_metrics': test_metrics
            }
        
        # 7.5. –ù–û–í–û–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info("\n" + "="*60)
        logger.info("üîç –®–ê–ì 7.5: –í–ê–õ–ò–î–ê–¶–ò–Ø –í–ê–ñ–ù–û–°–¢–ò –ü–†–ò–ó–ù–ê–ö–û–í")
        logger.info("="*60)
        
        validator = FeatureImportanceValidator(max_temporal_importance=3.0)
        validation_results = validator.validate_ensemble_importance(models, selected_features)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        if not validation_results['ensemble_validation']['valid']:
            severity = validation_results['ensemble_validation']['severity']
            if severity == 'critical':
                logger.error("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö!")
                logger.error("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–µ—Ä–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ!")
            else:
                logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = validator.get_recommendations()
            logger.info("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ:")
            for i, rec in enumerate(recommendations, 1):
                logger.info(f"   {i}. {rec}")
        else:
            logger.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞: –º–æ–¥–µ–ª—å –Ω–µ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö")
            
        # 8. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        logger.info("\n" + "="*60)
        logger.info("üìù –®–ê–ì 8: –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–ê")
        logger.info("="*60)
        
        report_generator = ReportGenerator(config, log_dir)
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        feature_importance_analysis = analyze_feature_importance(
            models, preprocessor.feature_names
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∞–Ω–∞–ª–∏–∑
        feature_importance_analysis['validation_results'] = validation_results
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç—á–µ—Ç–∞
        results = {
            'buy': models['buy']['test_metrics'],
            'sell': models['sell']['test_metrics'],
            'config': config,
            'n_features': X.shape[1],
            'n_samples': len(X),
            'feature_names': preprocessor.feature_names[:20],  # –¢–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            'feature_importance_analysis': feature_importance_analysis
        }
        
        report_generator.generate_report(results)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if config.training.save_plots:
            try:
                from utils.visualization import plot_feature_importance_by_category
                plot_path = log_dir / "feature_importance_by_category.png"
                plot_feature_importance_by_category(feature_importance_analysis, plot_path)
                logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {plot_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏: {e}")
        
        logger.info("\n" + "="*60)
        logger.info("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        logger.info(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {log_dir}")
        logger.info("="*60)
        
    except Exception as e:
        logger.error(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}", exc_info=True)
        raise
        

if __name__ == "__main__":
    main()