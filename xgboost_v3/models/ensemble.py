"""
–ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è XGBoost –º–æ–¥–µ–ª–µ–π
"""

import numpy as np
import pandas as pd
import logging
from typing import List, Dict, Tuple, Optional
from sklearn.metrics import roc_auc_score
import joblib

from models.xgboost_trainer import XGBoostTrainer
from config import Config
from config.constants import ENSEMBLE_PARAMS, EPSILON_STD

logger = logging.getLogger(__name__)


class EnsembleModel:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è XGBoost –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, config: Config):
        self.config = config
        self.models = []
        self.weights = None
        self.model_metrics = []
        
    def train_ensemble(self, 
                      X_train: pd.DataFrame,
                      y_train: pd.Series,
                      X_val: pd.DataFrame,
                      y_val: pd.Series,
                      n_models: Optional[int] = None) -> List[XGBoostTrainer]:
        """
        –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π
        
        Args:
            X_train: –û–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            y_train: –û–±—É—á–∞—é—â–∏–µ –º–µ—Ç–∫–∏
            X_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏  
            y_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            n_models: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤ –∞–Ω—Å–∞–º–±–ª–µ
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        """
        if n_models is None:
            n_models = self.config.training.ensemble_size
            
        logger.info(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∏–∑ {n_models} –º–æ–¥–µ–ª–µ–π")
        
        for i in range(n_models):
            logger.info(f"\nüìå –ú–æ–¥–µ–ª—å {i+1}/{n_models}")
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            model_params = self._get_diverse_params(i)
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            X_train_sub, y_train_sub = self._create_subsample(X_train, y_train, seed=i)
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            trainer = XGBoostTrainer(
                config=self.config,
                model_name=f"{self.config.training.task_type}_model_{i}"
            )
            
            trainer.train(
                X_train_sub, y_train_sub,
                X_val, y_val,
                model_params=model_params
            )
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
            metrics = trainer.evaluate(X_val, y_val, f"Validation (Model {i+1})")
            
            self.models.append(trainer)
            self.model_metrics.append(metrics)
            
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π
        self._calculate_weights(X_val, y_val)
        
        logger.info(f"\n‚úÖ –ê–Ω—Å–∞–º–±–ª—å –∏–∑ {n_models} –º–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω")
        self._log_ensemble_performance()
        
        return self.models
        
    def predict(self, X: pd.DataFrame, return_proba: bool = False) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
        
        Args:
            X: –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            return_proba: –í–µ—Ä–Ω—É—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            
        Returns:
            –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è
        """
        if not self.models:
            raise ValueError("–ê–Ω—Å–∞–º–±–ª—å –Ω–µ –æ–±—É—á–µ–Ω")
            
        predictions = []
        
        for model in self.models:
            pred = model.predict(X, return_proba=True)
            predictions.append(pred)
            
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = np.array(predictions)
        
        if self.config.training.ensemble_method == "weighted":
            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
            ensemble_pred = np.average(predictions, axis=0, weights=self.weights)
        elif self.config.training.ensemble_method == "voting":
            # –ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if self.config.training.task_type != "regression":
                # –ú–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
                threshold = ENSEMBLE_PARAMS['voting_threshold']
                binary_preds = (predictions > threshold).astype(int)
                ensemble_pred = np.mean(binary_preds, axis=0)
                if not return_proba:
                    ensemble_pred = (ensemble_pred > threshold).astype(int)
            else:
                ensemble_pred = np.mean(predictions, axis=0)
        else:
            # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
            ensemble_pred = np.mean(predictions, axis=0)
            
        if not return_proba and self.config.training.task_type == "classification_binary":
            ensemble_pred = (ensemble_pred > ENSEMBLE_PARAMS['voting_threshold']).astype(int)
            
        return ensemble_pred
        
    def evaluate(self, X: pd.DataFrame, y: pd.Series, dataset_name: str = "Test") -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ –∞–Ω—Å–∞–º–±–ª—è"""
        predictions = self.predict(X, return_proba=True)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º metrics calculator –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
        if self.models:
            metrics = self.models[0].metrics_calculator.calculate_classification_metrics(y, predictions)
            
            logger.info(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ {dataset_name}:")
            for metric_name, value in metrics.items():
                if isinstance(value, float):
                    logger.info(f"   {metric_name}: {value:.4f}")
                    
            return metrics
            
        return {}
        
    def save_ensemble(self, save_dir: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª—è"""
        logger.info(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è...")
        
        for i, model in enumerate(self.models):
            model.save_model(save_dir)
            
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –≤ Python —Ç–∏–ø—ã –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        def convert_to_native_types(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):
                return int(obj)
            elif isinstance(obj, (np.float64, np.float32, np.float16)):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_to_native_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_native_types(i) for i in obj]
            else:
                return obj
                
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω—Å–∞–º–±–ª—è
        ensemble_metadata = {
            'n_models': len(self.models),
            'weights': self.weights.tolist() if self.weights is not None else None,
            'model_metrics': convert_to_native_types(self.model_metrics),
            'ensemble_method': self.config.training.ensemble_method
        }
        
        import json
        from pathlib import Path
        
        metadata_path = Path(save_dir) / "ensemble_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(ensemble_metadata, f, indent=2, default=str)
            
        logger.info(f"‚úÖ –ê–Ω—Å–∞–º–±–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {save_dir}")
        
    def _get_diverse_params(self, model_idx: int) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª—è"""
        base_params = self.config.model.to_dict()
        
        # –í–∞—Ä—å–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        variations = ENSEMBLE_PARAMS['model_variations']
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏—é
        variation = variations[model_idx % len(variations)]
        base_params.update(variation)
        
        # –†–∞–∑–Ω—ã–µ random_state –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        base_params['random_state'] = 42 + model_idx
        
        return base_params
        
    def _create_subsample(self, X: pd.DataFrame, y: pd.Series, 
                         subsample_ratio: float = None, seed: int = 42) -> Tuple[pd.DataFrame, pd.Series]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if subsample_ratio is None:
            subsample_ratio = ENSEMBLE_PARAMS['subsample_ratio']
            
        np.random.seed(seed)
        
        n_samples = int(len(X) * subsample_ratio)
        # Bootstrap sampling –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        replace = ENSEMBLE_PARAMS.get('bootstrap', True)
        indices = np.random.choice(len(X), n_samples, replace=replace)
        
        return X.iloc[indices], y.iloc[indices]
        
    def _calculate_weights(self, X_val: pd.DataFrame, y_val: pd.Series):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if self.config.training.ensemble_method != "weighted":
            return
            
        logger.info("\nüìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π...")
        
        scores = []
        
        for i, model in enumerate(self.models):
            pred = model.predict(X_val, return_proba=True)
            
            if self.config.training.task_type == "regression":
                # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π MAE
                from sklearn.metrics import mean_absolute_error
                score = -mean_absolute_error(y_val, pred)
            else:
                # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º ROC-AUC
                try:
                    score = roc_auc_score(y_val, pred)
                except:
                    score = 0.5
                    
            scores.append(score)
            logger.info(f"   –ú–æ–¥–µ–ª—å {i+1}: score = {score:.4f}")
            
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
        scores = np.array(scores)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–±—Ä–æ—Å scores
        norm_params = ENSEMBLE_PARAMS['score_normalization']
        smoothing_params = ENSEMBLE_PARAMS['weight_smoothing']
        
        if scores.std() < norm_params['similarity_threshold']:  # –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏
            logger.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ—á–µ–Ω—å –±–ª–∏–∑–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞")
            self.weights = np.ones(len(scores)) / len(scores)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º softmax –¥–ª—è –±–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º scores –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤
            scores_normalized = (scores - scores.mean()) / (scores.std() + EPSILON_STD)
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            scores_normalized = np.clip(scores_normalized, 
                                       norm_params['clip_min'], 
                                       norm_params['clip_max'])
            # –ü—Ä–∏–º–µ–Ω—è–µ–º softmax
            exp_scores = np.exp(scores_normalized)
            self.weights = exp_scores / exp_scores.sum()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞
            if self.weights.max() > smoothing_params['extreme_weight_threshold']:
                logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞, –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ")
                # –°–≥–ª–∞–∂–∏–≤–∞–µ–º –≤–µ—Å–∞
                uniform_weights = np.ones(len(scores)) / len(scores)
                self.weights = (smoothing_params['model_weight'] * self.weights + 
                               smoothing_params['uniform_weight'] * uniform_weights)
        
        logger.info(f"   –í–µ—Å–∞: {self.weights}")
        
    def _log_ensemble_performance(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω—Å–∞–º–±–ª—è"""
        logger.info("\nüìä –°–≤–æ–¥–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º –∞–Ω—Å–∞–º–±–ª—è:")
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        summary = []
        for i, metrics in enumerate(self.model_metrics):
            if self.config.training.task_type == "regression":
                key_metric = metrics.get('mae', np.inf)
                metric_name = "MAE"
            else:
                key_metric = metrics.get('roc_auc', 0)
                metric_name = "ROC-AUC"
                
            summary.append({
                'Model': f"Model {i+1}",
                metric_name: key_metric,
                'Weight': self.weights[i] if self.weights is not None else 1/len(self.models)
            })
            
        summary_df = pd.DataFrame(summary)
        logger.info(f"\n{summary_df.to_string(index=False)}")
        
        # –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        avg_metric = summary_df[metric_name].mean()
        logger.info(f"\n–°—Ä–µ–¥–Ω–∏–π {metric_name}: {avg_metric:.4f}")