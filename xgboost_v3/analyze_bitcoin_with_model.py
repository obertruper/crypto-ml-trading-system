"""
–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ XGBoost –Ω–∞ –¥–∞–Ω–Ω—ã—Ö Bitcoin
"""

import pandas as pd
import numpy as np
import psycopg2
from psycopg2.extras import RealDictCursor
import json
import pickle
import logging
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BitcoinModelAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö Bitcoin"""
    
    def __init__(self, model_path: str):
        self.model_path = Path(model_path)
        self.connection = None
        self.models = {}
        self.feature_names = []
        self.threshold = 0.40  # –ü–æ—Ä–æ–≥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ (–ø–æ–≤—ã—à–µ–Ω–Ω—ã–π –¥–ª—è –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏)
        
    def connect_db(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        self.connection = psycopg2.connect(
            host='localhost',
            port=5555,
            database='crypto_trading',
            user='ruslan',
            password=''
        )
        logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        
    def analyze_database_expected_returns(self):
        """–ê–Ω–∞–ª–∏–∑ expected returns –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("\n" + "="*60)
        logger.info("üìä –ê–ù–ê–õ–ò–ó EXPECTED RETURNS –í –ë–ê–ó–ï –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        query = """
        SELECT 
            COUNT(*) as total_records,
            COUNT(buy_expected_return) as buy_records,
            COUNT(sell_expected_return) as sell_records,
            SUM(buy_expected_return) as sum_buy_expected,
            SUM(sell_expected_return) as sum_sell_expected,
            AVG(buy_expected_return) as avg_buy_expected,
            AVG(sell_expected_return) as avg_sell_expected,
            MIN(buy_expected_return) as min_buy_expected,
            MAX(buy_expected_return) as max_buy_expected,
            PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY buy_expected_return) as median_buy_expected
        FROM processed_market_data
        WHERE symbol = 'BTCUSDT'
        """
        
        with self.connection.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute(query)
            stats = cursor.fetchone()
            
        logger.info(f"üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        logger.info(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total_records']:,}")
        logger.info(f"   –°—É–º–º–∞ buy_expected_return: {stats['sum_buy_expected']:.2f}")
        logger.info(f"   –°—É–º–º–∞ sell_expected_return: {stats['sum_sell_expected']:.2f}")
        logger.info(f"   –°—Ä–µ–¥–Ω–∏–π buy_expected_return: {stats['avg_buy_expected']:.4f}%")
        logger.info(f"   –ú–µ–¥–∏–∞–Ω–∞ buy_expected_return: {stats['median_buy_expected']:.4f}%")
        logger.info(f"   –ú–∏–Ω/–ú–∞–∫—Å buy_expected_return: {stats['min_buy_expected']:.2f}% / {stats['max_buy_expected']:.2f}%")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
        ranges_query = """
        WITH ranges AS (
            SELECT 
                CASE 
                    WHEN buy_expected_return < -2 THEN '< -2%'
                    WHEN buy_expected_return >= -2 AND buy_expected_return < -1 THEN '-2% to -1%'
                    WHEN buy_expected_return >= -1 AND buy_expected_return < 0 THEN '-1% to 0%'
                    WHEN buy_expected_return >= 0 AND buy_expected_return < 1 THEN '0% to 1%'
                    WHEN buy_expected_return >= 1 AND buy_expected_return < 2 THEN '1% to 2%'
                    WHEN buy_expected_return >= 2 AND buy_expected_return < 3 THEN '2% to 3%'
                    ELSE '>= 3%'
                END as return_range,
                buy_expected_return,
                CASE 
                    WHEN buy_expected_return < -2 THEN 1
                    WHEN buy_expected_return >= -2 AND buy_expected_return < -1 THEN 2
                    WHEN buy_expected_return >= -1 AND buy_expected_return < 0 THEN 3
                    WHEN buy_expected_return >= 0 AND buy_expected_return < 1 THEN 4
                    WHEN buy_expected_return >= 1 AND buy_expected_return < 2 THEN 5
                    WHEN buy_expected_return >= 2 AND buy_expected_return < 3 THEN 6
                    ELSE 7
                END as sort_order
            FROM processed_market_data
            WHERE symbol = 'BTCUSDT'
        )
        SELECT 
            return_range,
            COUNT(*) as count,
            SUM(buy_expected_return) as sum_returns
        FROM ranges
        GROUP BY return_range, sort_order
        ORDER BY sort_order
        """
        
        logger.info(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ buy_expected_return –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º:")
        with self.connection.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute(ranges_query)
            ranges = cursor.fetchall()
            
        for r in ranges:
            pct = r['count'] / stats['total_records'] * 100
            logger.info(f"   {r['return_range']:12s}: {r['count']:7,} —Å–≤–µ—á–µ–π ({pct:5.1f}%) | –°—É–º–º–∞: {r['sum_returns']:10.2f}")
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–ø-10 —Ö—É–¥—à–∏—Ö expected returns
        worst_query = """
        SELECT timestamp, buy_expected_return
        FROM processed_market_data
        WHERE symbol = 'BTCUSDT'
        ORDER BY buy_expected_return ASC
        LIMIT 10
        """
        
        logger.info(f"\n‚ö†Ô∏è –¢–æ–ø-10 —Ö—É–¥—à–∏—Ö buy_expected_return:")
        with self.connection.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute(worst_query)
            worst = cursor.fetchall()
            
        for w in worst:
            dt = datetime.fromtimestamp(w['timestamp'] / 1000)
            logger.info(f"   {dt}: {w['buy_expected_return']:.2f}%")
            
        return stats
        
    def load_bitcoin_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Bitcoin —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏"""
        logger.info("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö BTCUSDT...")
        
        query = """
        SELECT 
            timestamp, open, high, low, close, volume,
            technical_indicators,
            buy_expected_return, 
            sell_expected_return
        FROM processed_market_data
        WHERE symbol = 'BTCUSDT'
        ORDER BY timestamp
        """
        
        with self.connection.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute(query)
            data = cursor.fetchall()
            
        df = pd.DataFrame(data)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤
        for col in ['open', 'high', 'low', 'close', 'volume', 'buy_expected_return', 'sell_expected_return']:
            df[col] = df[col].astype(float)
            
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        logger.info("   –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤...")
        indicators_data = []
        
        for idx, row in df.iterrows():
            if row['technical_indicators']:
                if isinstance(row['technical_indicators'], dict):
                    indicators = row['technical_indicators']
                else:
                    indicators = json.loads(row['technical_indicators'])
                indicators_data.append(indicators)
            else:
                indicators_data.append({})
                
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
        indicators_df = pd.DataFrame(indicators_data)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        df = pd.concat([df, indicators_df], axis=1)
        df.drop('technical_indicators', axis=1, inplace=True)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π —Å {len(indicators_df.columns)} –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        from feature_engineering_for_analysis import calculate_additional_features
        df = calculate_additional_features(df)
        
        return df
        
    def load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info(f"\nüíæ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑ {self.model_path}...")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –º–æ–¥–µ–ª–∏ (—Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
        self.feature_names = []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        model_file = self.model_path / "buy_models" / "classification_binary_model_0.pkl"
        if model_file.exists():
            with open(model_file, 'rb') as f:
                temp_model = pickle.load(f)
                if hasattr(temp_model, 'feature_names'):
                    self.feature_names = list(temp_model.feature_names)
                    logger.info(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –º–æ–¥–µ–ª–∏")
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ø-20 –∏–∑ metrics.json
        if not self.feature_names:
            metrics_path = self.model_path / "metrics.json"
            if metrics_path.exists():
                with open(metrics_path, 'r') as f:
                    metrics = json.load(f)
                    self.feature_names = metrics.get('feature_names', [])
                logger.info(f"   ‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ø-{len(self.feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ metrics.json")
            
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
        model_types = ['buy_profit', 'buy_loss', 'sell_profit', 'sell_loss']
        
        for model_type in model_types:
            if 'buy' in model_type:
                model_dir = self.model_path / "buy_models"
            else:
                model_dir = self.model_path / "sell_models"
                
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π (–æ–±—ã—á–Ω–æ classification_binary_model_*.pkl)
            model_files = list(model_dir.glob("classification_binary_model_*.pkl"))
            
            if model_files:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å –∏–∑ –∞–Ω—Å–∞–º–±–ª—è –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
                with open(model_files[0], 'rb') as f:
                    self.models[model_type] = pickle.load(f)
                logger.info(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å {model_type}")
            else:
                logger.warning(f"   ‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model_type} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                
    def prepare_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        logger.info("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        missing_features = []
        for feature in self.feature_names:
            if feature not in df.columns:
                missing_features.append(feature)
                
        if missing_features:
            logger.warning(f"   ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features[:10]}...")
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω—É–ª—è–º–∏
            for feature in missing_features:
                df[feature] = 0
                
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_df = df[self.feature_names].copy()
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        features_df = features_df.fillna(0)
        
        # –ó–∞–º–µ–Ω—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏
        features_df = features_df.replace([np.inf, -np.inf], 0)
        
        logger.info(f"   ‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(features_df.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        return features_df
        
    def generate_predictions(self, features_df: pd.DataFrame) -> Dict[str, np.ndarray]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
        logger.info("\nü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
        
        predictions = {}
        
        # –î–ª—è XGBoost Booster –∏—Å–ø–æ–ª—å–∑—É–µ–º predict –Ω–∞–ø—Ä—è–º—É—é
        import xgboost as xgb
        
        # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ buy_profit –∏ sell_profit
        if 'buy_profit' in self.models:
            # –°–æ–∑–¥–∞–µ–º DMatrix –¥–ª—è XGBoost
            dmatrix = xgb.DMatrix(features_df)
            buy_probs = self.models['buy_profit'].predict(dmatrix)
            predictions['buy_signals'] = buy_probs > self.threshold
            predictions['buy_probs'] = buy_probs
            logger.info(f"   ‚úÖ Buy —Å–∏–≥–Ω–∞–ª–æ–≤: {predictions['buy_signals'].sum():,}")
        
        if 'sell_profit' in self.models:
            dmatrix = xgb.DMatrix(features_df)
            sell_probs = self.models['sell_profit'].predict(dmatrix)
            predictions['sell_signals'] = sell_probs > self.threshold
            predictions['sell_probs'] = sell_probs
            logger.info(f"   ‚úÖ Sell —Å–∏–≥–Ω–∞–ª–æ–≤: {predictions['sell_signals'].sum():,}")
            
        return predictions
        
    def analyze_model_performance(self, df: pd.DataFrame, predictions: Dict[str, np.ndarray]):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        logger.info("\n" + "="*60)
        logger.info("üìä –ê–ù–ê–õ–ò–ó –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò –ú–û–î–ï–õ–ò")
        logger.info("="*60)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫ DataFrame
        df['buy_signal'] = predictions.get('buy_signals', False)
        df['sell_signal'] = predictions.get('sell_signals', False)
        df['buy_prob'] = predictions.get('buy_probs', 0)
        df['sell_prob'] = predictions.get('sell_probs', 0)
        
        # 1. –ê–Ω–∞–ª–∏–∑ Buy —Å–∏–≥–Ω–∞–ª–æ–≤
        logger.info("\nüîµ BUY –°–ò–ì–ù–ê–õ–´:")
        buy_signals_df = df[df['buy_signal']]
        logger.info(f"   –í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(buy_signals_df):,} –∏–∑ {len(df):,} ({len(buy_signals_df)/len(df)*100:.1f}%)")
        
        if len(buy_signals_df) > 0:
            buy_sum = buy_signals_df['buy_expected_return'].sum()
            buy_mean = buy_signals_df['buy_expected_return'].mean()
            buy_median = buy_signals_df['buy_expected_return'].median()
            buy_positive = (buy_signals_df['buy_expected_return'] > 0).sum()
            buy_above_threshold = (buy_signals_df['buy_expected_return'] > 1.5).sum()
            
            logger.info(f"   –°—É–º–º–∞ expected returns: {buy_sum:.2f} (vs -91,568.92 –¥–ª—è –≤—Å–µ—Ö)")
            logger.info(f"   –°—Ä–µ–¥–Ω–∏–π expected return: {buy_mean:.4f}%")
            logger.info(f"   –ú–µ–¥–∏–∞–Ω–∞ expected return: {buy_median:.4f}%")
            logger.info(f"   –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {buy_positive:,} ({buy_positive/len(buy_signals_df)*100:.1f}%)")
            logger.info(f"   –í—ã—à–µ –ø–æ—Ä–æ–≥–∞ 1.5%: {buy_above_threshold:,} ({buy_above_threshold/len(buy_signals_df)*100:.1f}%)")
            
        # 2. –ê–Ω–∞–ª–∏–∑ Sell —Å–∏–≥–Ω–∞–ª–æ–≤
        logger.info("\nüî¥ SELL –°–ò–ì–ù–ê–õ–´:")
        sell_signals_df = df[df['sell_signal']]
        logger.info(f"   –í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(sell_signals_df):,} –∏–∑ {len(df):,} ({len(sell_signals_df)/len(df)*100:.1f}%)")
        
        if len(sell_signals_df) > 0:
            sell_sum = sell_signals_df['sell_expected_return'].sum()
            sell_mean = sell_signals_df['sell_expected_return'].mean()
            sell_median = sell_signals_df['sell_expected_return'].median()
            sell_positive = (sell_signals_df['sell_expected_return'] > 0).sum()
            sell_above_threshold = (sell_signals_df['sell_expected_return'] > 1.5).sum()
            
            logger.info(f"   –°—É–º–º–∞ expected returns: {sell_sum:.2f}")
            logger.info(f"   –°—Ä–µ–¥–Ω–∏–π expected return: {sell_mean:.4f}%")
            logger.info(f"   –ú–µ–¥–∏–∞–Ω–∞ expected return: {sell_median:.4f}%")
            logger.info(f"   –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {sell_positive:,} ({sell_positive/len(sell_signals_df)*100:.1f}%)")
            logger.info(f"   –í—ã—à–µ –ø–æ—Ä–æ–≥–∞ 1.5%: {sell_above_threshold:,} ({sell_above_threshold/len(sell_signals_df)*100:.1f}%)")
            
        # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–¥–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ–π
        logger.info("\nüéØ –°–†–ê–í–ù–ï–ù–ò–ï –° –ò–î–ï–ê–õ–¨–ù–û–ô –¢–û–†–ì–û–í–õ–ï–ô:")
        
        # –ò–¥–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è - —Ç–æ–ª—å–∫–æ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ —Å–¥–µ–ª–∫–∏
        ideal_buy = df[df['buy_expected_return'] > 1.5]
        ideal_sell = df[df['sell_expected_return'] > 1.5]
        
        logger.info(f"   –ò–¥–µ–∞–ª—å–Ω—ã—Ö buy —Å–∏–≥–Ω–∞–ª–æ–≤: {len(ideal_buy):,}")
        logger.info(f"   –ò–¥–µ–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ buy: {ideal_buy['buy_expected_return'].sum():.2f}")
        logger.info(f"   –ú–æ–¥–µ–ª—å –Ω–∞—à–ª–∞ buy: {len(buy_signals_df):,} ({len(buy_signals_df)/len(ideal_buy)*100:.1f}% –æ—Ç –∏–¥–µ–∞–ª–∞)")
        
        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ - —Å–∫–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        if len(buy_signals_df) > 0:
            correct_buy = df[df['buy_signal'] & (df['buy_expected_return'] > 1.5)]
            precision = len(correct_buy) / len(buy_signals_df) * 100
            recall = len(correct_buy) / len(ideal_buy) * 100
            logger.info(f"   Precision (—Ç–æ—á–Ω–æ—Å—Ç—å): {precision:.1f}%")
            logger.info(f"   Recall (–ø–æ–ª–Ω–æ—Ç–∞): {recall:.1f}%")
            
        return df
        
    def save_results(self, df: pd.DataFrame):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        output_dir = Path("analysis_results")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        output_file = output_dir / f"bitcoin_predictions_{timestamp}.csv"
        df.to_csv(output_file, index=False)
        logger.info(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∏–≥–Ω–∞–ª—ã
        signals_df = df[df['buy_signal'] | df['sell_signal']]
        signals_file = output_dir / f"bitcoin_signals_{timestamp}.csv"
        signals_df.to_csv(signals_file, index=False)
        logger.info(f"üíæ –°–∏–≥–Ω–∞–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {signals_file}")
        
    def visualize_results(self, df: pd.DataFrame):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ expected returns
        ax = axes[0, 0]
        ax.hist(df['buy_expected_return'], bins=100, alpha=0.5, label='–í—Å–µ —Å–≤–µ—á–∏', color='blue')
        buy_signals_returns = df[df['buy_signal']]['buy_expected_return']
        if len(buy_signals_returns) > 0:
            ax.hist(buy_signals_returns, bins=50, alpha=0.7, label='–°–∏–≥–Ω–∞–ª—ã –º–æ–¥–µ–ª–∏', color='green')
        ax.axvline(0, color='red', linestyle='--', alpha=0.5)
        ax.axvline(1.5, color='orange', linestyle='--', alpha=0.5, label='–ü–æ—Ä–æ–≥ 1.5%')
        ax.set_xlabel('Buy Expected Return (%)')
        ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Buy Expected Returns')
        ax.legend()
        ax.set_xlim(-5, 10)
        
        # 2. –ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –ø—Ä–∏–±—ã–ª—å
        ax = axes[0, 1]
        df_sorted = df.sort_values('timestamp')
        
        # –í—Å–µ —Å–¥–µ–ª–∫–∏
        cumsum_all = df_sorted['buy_expected_return'].cumsum()
        ax.plot(cumsum_all.values, label='–í—Å–µ —Å–¥–µ–ª–∫–∏', alpha=0.5, color='red')
        
        # –¢–æ–ª—å–∫–æ —Å–∏–≥–Ω–∞–ª—ã –º–æ–¥–µ–ª–∏
        model_returns = df_sorted['buy_expected_return'].where(df_sorted['buy_signal'], 0)
        cumsum_model = model_returns.cumsum()
        ax.plot(cumsum_model.values, label='–°–∏–≥–Ω–∞–ª—ã –º–æ–¥–µ–ª–∏', color='green', linewidth=2)
        
        # –ò–¥–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        ideal_returns = df_sorted['buy_expected_return'].where(df_sorted['buy_expected_return'] > 1.5, 0)
        cumsum_ideal = ideal_returns.cumsum()
        ax.plot(cumsum_ideal.values, label='–ò–¥–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è', color='blue', linestyle='--')
        
        ax.set_xlabel('–ù–æ–º–µ—Ä —Å–≤–µ—á–∏')
        ax.set_ylabel('–ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π Return (%)')
        ax.set_title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –ø—Ä–∏–±—ã–ª—å')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 3. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ vs Expected Return
        ax = axes[1, 0]
        if 'buy_prob' in df.columns:
            scatter_data = df.sample(min(10000, len(df)))  # –ë–µ—Ä–µ–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            colors = ['green' if x > 1.5 else 'red' for x in scatter_data['buy_expected_return']]
            ax.scatter(scatter_data['buy_prob'], scatter_data['buy_expected_return'], 
                      alpha=0.3, c=colors, s=1)
            ax.axhline(1.5, color='orange', linestyle='--', alpha=0.5)
            ax.axvline(self.threshold, color='blue', linestyle='--', alpha=0.5)
            ax.set_xlabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏')
            ax.set_ylabel('Buy Expected Return (%)')
            ax.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å vs Expected Return')
            ax.set_ylim(-5, 10)
        
        # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        ax = axes[1, 1]
        df['hour'] = pd.to_datetime(df['timestamp'], unit='ms').dt.hour
        hourly_stats = df.groupby('hour').agg({
            'buy_expected_return': 'mean',
            'buy_signal': 'sum'
        })
        
        ax2 = ax.twinx()
        ax.bar(hourly_stats.index, hourly_stats['buy_signal'], alpha=0.5, label='–ö–æ–ª-–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤')
        ax2.plot(hourly_stats.index, hourly_stats['buy_expected_return'], 
                color='red', marker='o', label='–°—Ä–µ–¥–Ω–∏–π return')
        
        ax.set_xlabel('–ß–∞—Å –¥–Ω—è')
        ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤')
        ax2.set_ylabel('–°—Ä–µ–¥–Ω–∏–π Expected Return (%)')
        ax.set_title('–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å–∞–º')
        ax.legend(loc='upper left')
        ax2.legend(loc='upper right')
        
        plt.tight_layout()
        
        output_file = "analysis_results/bitcoin_analysis_charts.png"
        plt.savefig(output_file, dpi=300)
        logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        plt.close()

def main():
    # –ü—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –º–æ–¥–µ–ª–∏
    model_path = "/Users/ruslan/PycharmProjects/LLM TRANSFORM/logs_from_gpu/xgboost_v3_20250616_070913"
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = BitcoinModelAnalyzer(model_path)
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        analyzer.connect_db()
        
        # –ê–Ω–∞–ª–∏–∑ expected returns –≤ –ë–î
        db_stats = analyzer.analyze_database_expected_returns()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ Bitcoin
        df = analyzer.load_bitcoin_data()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
        analyzer.load_models()
        
        if analyzer.models and analyzer.feature_names:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features_df = analyzer.prepare_features(df)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = analyzer.generate_predictions(features_df)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            results_df = analyzer.analyze_model_performance(df, predictions)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            analyzer.visualize_results(results_df)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            analyzer.save_results(results_df)
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if analyzer.connection:
            analyzer.connection.close()
            logger.info("\n‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")

if __name__ == "__main__":
    main()