#!/usr/bin/env python3
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏ –ø–æ 10,000 –∑–∞–ø–∏—Å–µ–π
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã —Å –∫–æ–º–º–∏—Ç–∞–º–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
"""

import psycopg2
import yaml
import logging
import time
from datetime import datetime
from tqdm import tqdm

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def fix_data_leakage_batches():
    """–£–¥–∞–ª—è–µ—Ç expected_returns –∏–∑ technical_indicators –±–∞—Ç—á–∞–º–∏ –ø–æ 10k"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    db_config = config['database'].copy()
    if not db_config.get('password'):
        db_config.pop('password', None)
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
    conn = psycopg2.connect(**db_config)
    conn.autocommit = False  # –£–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏ –≤—Ä—É—á–Ω—É—é
    
    logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    
    try:
        cursor = conn.cursor()
        
        # 1. –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π —Å —É—Ç–µ—á–∫–æ–π
        logger.info("\nüîç –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
        cursor.execute("""
            SELECT COUNT(*) 
            FROM processed_market_data 
            WHERE technical_indicators ?| array['buy_expected_return', 'sell_expected_return']
        """)
        total_with_leak = cursor.fetchone()[0]
        
        logger.info(f"   –ó–∞–ø–∏—Å–µ–π —Å —É—Ç–µ—á–∫–æ–π: {total_with_leak:,}")
        
        if total_with_leak == 0:
            logger.info("‚úÖ –£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
            return
        
        # 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        logger.info("\n‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ PostgreSQL...")
        cursor.execute("SET work_mem = '256MB'")
        cursor.execute("SET maintenance_work_mem = '512MB'")
        conn.commit()
        
        # 3. –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å ID –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        logger.info("\nüìã –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ ID –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        cursor.execute("DROP TABLE IF EXISTS temp_leak_ids")
        cursor.execute("""
            CREATE TEMP TABLE temp_leak_ids AS
            SELECT id 
            FROM processed_market_data 
            WHERE technical_indicators ?| array['buy_expected_return', 'sell_expected_return']
            ORDER BY id
        """)
        cursor.execute("CREATE INDEX idx_temp_leak_ids ON temp_leak_ids(id)")
        cursor.execute("ANALYZE temp_leak_ids")
        conn.commit()
        
        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏ –ø–æ 10,000
        batch_size = 10000
        processed = 0
        start_time = time.time()
        failed_batches = 0
        last_logged = 0  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        
        logger.info(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É –±–∞—Ç—á–∞–º–∏ –ø–æ {batch_size:,} –∑–∞–ø–∏—Å–µ–π...")
        
        with tqdm(total=total_with_leak, desc="–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö", unit="–∑–∞–ø–∏—Å–µ–π") as pbar:
            while processed < total_with_leak:
                batch_start = time.time()
                
                try:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞—Ç—á —á–µ—Ä–µ–∑ JOIN —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ–π (–±–µ–∑ ORDER BY –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
                    cursor.execute("""
                        UPDATE processed_market_data p
                        SET technical_indicators = p.technical_indicators 
                            - 'buy_expected_return'::text 
                            - 'sell_expected_return'::text
                        FROM (
                            SELECT id FROM temp_leak_ids
                            LIMIT %s OFFSET %s
                        ) t
                        WHERE p.id = t.id
                    """, (batch_size, processed))
                    
                    batch_updated = cursor.rowcount
                    
                    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ, –Ω–æ –º—ã –Ω–µ –≤ –∫–æ–Ω—Ü–µ - –ø—Ä–æ–±–ª–µ–º–∞
                    if batch_updated == 0 and processed < total_with_leak:
                        logger.warning(f"‚ö†Ô∏è –ë–∞—Ç—á {processed//batch_size + 1} –≤–µ—Ä–Ω—É–ª 0 –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π")
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –±–∞—Ç—á
                        processed += batch_size
                        continue
                    
                    # –ö–æ–º–º–∏—Ç–∏–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
                    conn.commit()
                    
                    processed += batch_updated
                    pbar.update(batch_updated)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    batch_time = time.time() - batch_start
                    total_elapsed = time.time() - start_time
                    speed = processed / total_elapsed if total_elapsed > 0 else 0
                    remaining_records = total_with_leak - processed
                    eta = remaining_records / speed if speed > 0 else 0
                    
                    pbar.set_postfix({
                        '–ë–∞—Ç—á': f'{batch_time:.1f}—Å',
                        '–°–∫–æ—Ä–æ—Å—Ç—å': f'{speed:.0f} –∑–∞–ø/—Å',
                        'ETA': f'{eta/60:.1f} –º–∏–Ω'
                    })
                    
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–∞–∂–¥—ã–µ 100k –∑–∞–ø–∏—Å–µ–π
                    if processed - last_logged >= 100000:
                        logger.info(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed:,} –∑–∞–ø–∏—Å–µ–π ({processed/total_with_leak*100:.1f}%)")
                        last_logged = processed
                    
                    # –ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–æ –º–µ–Ω—å—à–µ batch_size, –∑–Ω–∞—á–∏—Ç –∑–∞–∫–æ–Ω—á–∏–ª–∏
                    if batch_updated < batch_size:
                        break
                        
                except Exception as e:
                    failed_batches += 1
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {processed//batch_size + 1}: {e}")
                    conn.rollback()
                    
                    if failed_batches > 3:
                        logger.error("‚ùå –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É")
                        raise
                    
                    # –ù–ï —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º processed –ø—Ä–∏ –æ—à–∏–±–∫–µ - –ø–æ–ø—Ä–æ–±—É–µ–º —ç—Ç–æ—Ç –±–∞—Ç—á —Å–Ω–æ–≤–∞
                    time.sleep(1)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    continue
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = time.time() - start_time
        logger.info(f"\n‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed:,} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"   –í—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫ ({total_time/60:.1f} –º–∏–Ω)")
        logger.info(f"   –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {processed/total_time:.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
        
        if failed_batches > 0:
            logger.warning(f"   ‚ö†Ô∏è –ë—ã–ª–æ {failed_batches} –æ—à–∏–±–æ–∫ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ")
        
        # 4. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        logger.info("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        cursor.execute("""
            SELECT COUNT(*) 
            FROM processed_market_data 
            WHERE technical_indicators ?| array['buy_expected_return', 'sell_expected_return']
        """)
        remaining = cursor.fetchone()[0]
        
        if remaining == 0:
            logger.info("‚úÖ –£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∞!")
            
            # 5. –û—á–∏—Å—Ç–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
            logger.info("\nüßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            cursor.execute("DROP TABLE IF EXISTS temp_leak_ids")
            conn.commit()
            
            logger.info("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã (VACUUM ANALYZE)...")
            conn.autocommit = True
            cursor.execute("VACUUM ANALYZE processed_market_data")
            logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
        else:
            logger.warning(f"‚ö†Ô∏è –û—Å—Ç–∞–ª–∏—Å—å –∑–∞–ø–∏—Å–∏ —Å —É—Ç–µ—á–∫–æ–π: {remaining:,}")
            logger.info("   –í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫—Ä–∏–ø—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ")
            
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è –û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        conn.rollback()
        raise
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()
        logger.info("\nüì§ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL –∑–∞–∫—Ä—ã—Ç–æ")


if __name__ == "__main__":
    logger.info("üöÄ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏ –ø–æ 10,000")
    logger.info("=" * 60)
    logger.info("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –∫–æ–º–º–∏—Ç–∞–º–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞")
    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
    logger.info("–û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 3-5 –º–∏–Ω—É—Ç –¥–ª—è 2.5–ú –∑–∞–ø–∏—Å–µ–π")
    logger.info("=" * 60)
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    response = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ")
    if response.lower() == 'y':
        try:
            fix_data_leakage_batches()
        except KeyboardInterrupt:
            logger.info("\n‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            logger.error(f"\n‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
            import traceback
            traceback.print_exc()
    else:
        logger.info("–û—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")